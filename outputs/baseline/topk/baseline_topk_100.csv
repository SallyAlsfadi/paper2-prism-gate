rank_priority_only,issue_key,project,created_ts,updated_ts,issue_type,status,priority,priority_ordinal,text_len,text
1,AIRFLOW-56,AIRFLOW,1462536460000,1462871357000,Bug,Closed,Blocker,1,531,"Airflow's scheduler can ""lose"" queued tasks Tasks that get into queued status can get ""lost"" on the scheduler/executor. They remain in the DB with state ""queued"", but the scheduler won't pick them up as it will not look at the DB currently. The executor does not see those tasks, although the scheduler has NOT been restarted (ie. to see this issue it is not required to have ""-n x"" as a parameter to the scheduler). This happens *also* to tasks scheduled by the scheduler and not just with backfills created by the SubDagOperator."
2,AIRFLOW-106,AIRFLOW,1462985047000,1463126376000,Bug,Closed,Blocker,1,2999,"Task Retries, on_failure callback, and email_on_failure Not Honored if First Task in a DAG Fails Hello. I created the following workflow : {code} from airflow import DAG from airflow.operators import PythonOperator from datetime import datetime, timedelta from airflow.models import Variable from time import sleep default_args = { 'depends_on_past': False, 'start_date': datetime(2016, 5, 11, 15, 20), 'email': <my email> 'email_on_failure': True, 'email_on_retry': False, 'retries': 1, 'retry_delay': timedelta(minutes=2), 'end_date': datetime(2016, 5, 11, 16, 00), } PARENT_DAG_NAME = 'test' dag = DAG(PARENT_DAG_NAME, default_args=default_args, schedule_interval=timedelta(minutes=10)) def sleep1_function(**kwargs): sleep(90) return Variable.get('test_var') sleep1 = PythonOperator( task_id='sleep1', python_callable=sleep1_function, dag=dag) {code} I forgot to declare test_var so when this DAG launched it failed quickly. However no failure email was ever sent. Clearing the failed task to make it rerun doesn't trigger any email. Here is the logs : {code} [2016-05-11 15:53:31,784] {models.py:157} INFO - Filling up the DagBag from /var/lib/airflow/airflow/dags/test.py [2016-05-11 15:53:32,272] {models.py:157} INFO - Filling up the DagBag from /var/lib/airflow/airflow/dags/test.py [2016-05-11 15:53:32,313] {models.py:1216} INFO - -------------------------------------------------------------------------------- Starting attempt 1 of 2 -------------------------------------------------------------------------------- [2016-05-11 15:53:32,333] {models.py:1239} INFO - Executing <Task(PythonOperator): sleep1> on 2016-05-11 15:20:00 [2016-05-11 15:55:03,450] {models.py:1306} ERROR - Variable test_var does not exist Traceback (most recent call last): File ""/usr/local/lib/python2.7/dist-packages/airflow-1.7.0-py2.7.egg/airflow/models.py"", line 1265, in run result = task_copy.execute(context=context) File ""/usr/local/lib/python2.7/dist-packages/airflow-1.7.0-py2.7.egg/airflow/operators/python_operator.py"", line 66, in execute return_value = self.python_callable(*self.op_args, **self.op_kwargs) File ""/var/lib/airflow/airflow/dags/test.py"", line 31, in sleep1_function return Variable.get('test_var') File ""/usr/local/lib/python2.7/dist-packages/airflow-1.7.0-py2.7.egg/airflow/utils/db.py"", line 53, in wrapper result = func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/airflow-1.7.0-py2.7.egg/airflow/models.py"", line 3145, in get raise ValueError('Variable {} does not exist'.format(key)) ValueError: Variable test_var does not exist [2016-05-11 15:55:03,581] {models.py:1318} INFO - Marking task as UP_FOR_RETRY [2016-05-11 15:55:03,759] {models.py:1347} ERROR - Variable test_var does not exist {code} In the DAG Runs page, the workflow is set as failed. In hte taks instance page, it is set as up_for_retry but no new run is ever scheduled. I tried incrementing the retires parameter, but nothing different happens, Airflow never retries after the first run. dud"
3,AIRFLOW-434,AIRFLOW,1471385417000,1475022298000,Bug,Resolved,Blocker,1,2555,"max_dag_run_reached blocks dag state change and new task scheduling Using the following DAG: ``` from airflow import DAG from airflow.operators.bash_operator import BashOperator from datetime import datetime, timedelta default_args = { 'owner': 'airflow', 'depends_on_past': False, 'start_date': datetime(2016, 1, 1, 1, 0), 'email': ['xuanji@gmail.com'], 'email_on_failure': True, 'email_on_retry': False, 'retries': 3, 'retry_delay': timedelta(minutes=1), } dag = DAG('bash_bash_bash', default_args=default_args, schedule_interval=timedelta(seconds=10)) # t1, t2 and t3 are examples of tasks created by instatiating operators t1 = BashOperator( task_id='print_date', bash_command='date', dag=dag) t2 = BashOperator( task_id='sleep', bash_command='sleep 120', retries=3, dag=dag) templated_command = """""" {% for i in range(5) %} echo ""{{ ds }}"" echo ""{{ macros.ds_add(ds, 7)}}"" echo ""{{ params.my_param }}"" {% endfor %} """""" t3 = BashOperator( task_id='templated', bash_command=templated_command, params={'my_param': 'Parameter I passed in'}, dag=dag) t2.set_upstream(t1) t3.set_upstream(t1) ``` and an `airflow.cfg` that contains this: ``` min_file_process_interval = 1 ``` The state eventually becomes this: http://imgur.com/a/5bRTe The scheduler should be marking the 14 leftmost dagruns as success, but does not. the scheduler should also be scheduling tasks for the last two dagruns. A look at the logs explains the probable cause: ``` [2016-08-16 15:12:10,257] {jobs.py:1446} DagFileProcessor174 INFO - Processing file /Users/xuanji_li/airflow/dags/bash_bash_bash.py for tasks to queue [2016-08-16 15:12:10,258] {models.py:162} DagFileProcessor174 INFO - Filling up the DagBag from /Users/xuanji_li/airflow/dags/bash_bash_bash.py [2016-08-16 15:12:10,267] {jobs.py:1460} DagFileProcessor174 INFO - DAG(s) ['bash_bash_bash'] retrieved from /Users/xuanji_li/airflow/dags/bash_bash_bash.py [2016-08-16 15:12:10,289] {jobs.py:1062} DagFileProcessor174 INFO - Not processing DAG bash_bash_bash since its max runs has been reached [2016-08-16 15:12:10,290] {models.py:313} DagFileProcessor174 INFO - Finding 'running' jobs without a recent heartbeat [2016-08-16 15:12:10,290] {models.py:319} DagFileProcessor174 INFO - Failing jobs without heartbeat after 2016-08-16 15:09:55.290479 ``` It seems that processing of the dagrun is skipped completely because there are already 16 running dagruns. Binary search tracked down this commit as the one that introduced the bug. The logic added looks wrong to me. https://github.com/apache/incubator-airflow/pull/1716"
4,AIRFLOW-447,AIRFLOW,1471590020000,1472737415000,Bug,Resolved,Blocker,1,683,"Python 3 map object cannot be json-serialized - need lists instead On this line, `source_uris` are generated with `map`: https://github.com/apache/incubator-airflow/blob/master/airflow/contrib/operators/gcs_to_bq.py#L124 In Python 2 `map` would return a list, however in Python 3 `map` returns a `map` object / generator. The Python 3 `map` object cannot be json-serialized downstream when storing corresponding job objects in the database: https://github.com/apache/incubator-airflow/blob/master/airflow/contrib/hooks/bigquery_hook.py#L441 Constructing `source_uris` with a list comprehension instead of `map` resolves the issue for Python 3 and retains compatibility with Python 2."
5,AIRFLOW-607,AIRFLOW,1477931169000,1490736678000,Bug,Resolved,Blocker,1,851,"Cannot initdb on Oracle because of String(5000) fields in model Unfortunately Oracle cannot be used to host the Airflow application DB due to the fact that Oracle limits varchar data types to 4000 bytes. If you try to run the airflow initdb command to install the DB onto Oracle you will end up with the following error: sqlalchemy.exc.DatabaseError: (cx_Oracle.DatabaseError) ORA-00910: specified length too long for its datatype [SQL: '\nCREATE TABLE connection (\n\tid INTEGER NOT NULL, \n\tconn_id VARCHAR2(250 CHAR), \n\tconn_type VARCHAR2(500 CHAR), \n\thost VARCHAR2(500 CHAR), \n\tschema VARCHAR2(500 CHAR), \n\tlogin VARCHAR2(500 CHAR), \n\tpassword VARCHAR2(500 CHAR), \n\tport INTEGER, \n\textra VARCHAR2(5000 CHAR), \n\tPRIMARY KEY (id)\n)\n\n'] Request that we change String(5000) types in the Chart and Connection models to 4000. Thanks!"
6,AIRFLOW-660,AIRFLOW,1480515716000,1558123380000,Bug,Resolved,Blocker,1,2682,"Impossible to record second task failure {code} /var/log/airflow/airflow_scheduler_err.log.10: [SQL: 'INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s)'] [parameters: {'task_id': 'test_task', 'end_date': datetime.datetime(2016, 11, 30, 14, 38, 39, 197485), 'execution_date': datetime.datetime(2016, 11, 30, 0, 0), 'duration': 331.723087, 'start_date': datetime.datetime(2016, 11, 30, 14, 33, 7, 474398), 'dag_id': 'test_dag'}] /var/log/airflow/airflow_scheduler_err.log.10-Process DagFileProcessor314-Process: /var/log/airflow/airflow_scheduler_err.log.10-Traceback (most recent call last): /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/multiprocessing/process.py"", line 258, in _bootstrap /var/log/airflow/airflow_scheduler_err.log.10- self.run() /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/multiprocessing/process.py"", line 114, in run /var/log/airflow/airflow_scheduler_err.log.10- self._target(*self._args, **self._kwargs) /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/site-packages/airflow/jobs.py"", line 318, in helper /var/log/airflow/airflow_scheduler_err.log.10- pickle_dags) /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/site-packages/airflow/utils/db.py"", line 56, in wrapper /var/log/airflow/airflow_scheduler_err.log.10- session.commit() /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/site-packages/sqlalchemy/orm/session.py"", line 813, in commit /var/log/airflow/airflow_scheduler_err.log.10- self.transaction.commit() /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/site-packages/sqlalchemy/orm/session.py"", line 390, in commit /var/log/airflow/airflow_scheduler_err.log.10- self._assert_active(prepared_ok=True) /var/log/airflow/airflow_scheduler_err.log.10- File ""/usr/local/lib/python2.7/site-packages/sqlalchemy/orm/session.py"", line 214, in _assert_active /var/log/airflow/airflow_scheduler_err.log.10- % self._rollback_exception /var/log/airflow/airflow_scheduler_err.log.10:InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.IntegrityError) duplicate key value violates unique constraint ""task_fail_pkey"" /var/log/airflow/airflow_scheduler_err.log.10-DETAIL: Key (task_id, dag_id, execution_date)=(test_dag, test_task, 2016-11-30 00:00:00) already exists. {code}"
7,AIRFLOW-695,AIRFLOW,1481580870000,1542279432000,Bug,Closed,Blocker,1,910,"Retries do not execute because dagrun is in FAILED state Currently on the latest master commit (15ff540ecd5e60e7ce080177ea3ea227582a4672), running on the LocalExecutor, retries on tasks do not execute because the state of the corresponding dagrun changes to FAILED. The task instance then gets blocked because ""Task instance's dagrun was not in the 'running' state but in the state 'failed',"" the error message produced by the following lines: https://github.com/apache/incubator-airflow/blob/master/airflow/ti_deps/deps/dagrun_exists_dep.py#L48-L50 This error can be reproduced with the following simple DAG: {code:title=DAG.py|borderStyle=solid} dag = models.DAG(dag_id='test_retry_handling') task = BashOperator( task_id='test_retry_handling_op', bash_command='exit 1', retries=1, retry_delay=datetime.timedelta(minutes=1), dag=dag, owner='airflow', start_date=datetime.datetime(2016, 2, 1, 0, 0, 0)) {code}"
8,AIRFLOW-719,AIRFLOW,1482857456000,1541102707000,Sub-task,Closed,Blocker,1,251,"Skipped operations make DAG finish prematurely Since revision 2630361ca24737c28f458825b20ab11c9c996b17 the SKIPPED and SUCCESS are treated the same, this causes the DAG to finish prematurely when using a Branching operator where on branch is finished."
9,AIRFLOW-727,AIRFLOW,1483390477000,1490374009000,Bug,Resolved,Blocker,1,210,"try_number is not increased A dag that has retries enabled will retry indefinitely as try_number gets reset to 0 in LocalTaskJob as task_instance is not fully populated, but nevertheless saved to the databases."
10,AIRFLOW-738,AIRFLOW,1483735453000,1535980834000,Bug,Resolved,Blocker,1,5821,"XCom: Deadlock found when trying to get lock; try restarting transaction When using the following dag: {code} from datetime import datetime, timedelta import logging import pprint import random # The DAG object; we'll need this to instantiate a DAG from airflow import DAG # Operators; we need this to operate! from airflow.operators.python_operator import PythonOperator start_time = datetime.now().replace(minute=0, second=0, microsecond=0) start_time += timedelta(hours=-1) # timedelta(days=-2) default_args = { 'owner': 'airflow', 'depends_on_past': False, 'start_date': start_time, 'email': ['alex.papanic@gmail.com'], 'email_on_failure': True, 'email_on_retry': True, 'retries': 1, 'retry_delay': timedelta(minutes=1) # 'queue': 'bash_queue', # 'pool': 'backfill', # 'priority_weight': 10, # 'end_date': datetime(2016, 1, 1), } dag = DAG( 'xcom_test', default_args=default_args, schedule_interval='@once') def upload_activity_status(pgconn_id, **context): upstream_task_ids = context['task'].upstream_task_ids logging.info( ""Getting status from upstream task {}"".format(upstream_task_ids)) status = context['ti'].xcom_pull(task_ids=upstream_task_ids) logging.info(""Xcom pull results:\n{}"".format(pprint.pformat(status))) logging.info(""Upload to DB here"") upload_ativity_status = PythonOperator( task_id='upload_activity_status', python_callable=upload_activity_status, op_kwargs={'pgconn_id': 'postgres_conn'}, provide_context=True, dag=dag) def poll_data(params, execution_date, **context): logging.info(""Test polling function for {data_stream}"".format(**params)) status = random.random() < 0.5 output = dict( data_stream=params['data_stream'], timeperiod=execution_date + timedelta(hours=-1), status=status ) return output def poll_data_factory(data_stream, dag): return PythonOperator( task_id='poll_{}'.format(data_stream), python_callable=poll_data, params={u'data_stream': data_stream}, provide_context=True, dag=dag ) poll_streams = [] streams = ['stream' + str(i) for i in range(30)] for data_stream in streams: poll = poll_data_factory(data_stream, dag) poll_streams.append(poll) upload_ativity_status.set_upstream(poll) {code} The following error is thrown: {code} 2017-01-06 21:41:35,824] {jobs.py:1433} INFO - Heartbeating the scheduler Traceback (most recent call last): File ""/Users/bolke/Documents/dev/airflow_env/bin/airflow"", line 4, in <module> __import__('pkg_resources').run_script('airflow==1.7.2.dev0', 'airflow') File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/pkg_resources/__init__.py"", line 739, in run_script self.require(requires)[0].run_script(script_name, ns) File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/pkg_resources/__init__.py"", line 1494, in run_script exec(code, namespace, namespace) File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/airflow-1.7.2.dev0-py2.7.egg/EGG-INFO/scripts/airflow"", line 28, in <module> args.func(args) File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/airflow-1.7.2.dev0-py2.7.egg/airflow/bin/cli.py"", line 380, in run pool=args.pool, File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/airflow-1.7.2.dev0-py2.7.egg/airflow/utils/db.py"", line 54, in wrapper result = func(*args, **kwargs) File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/airflow-1.7.2.dev0-py2.7.egg/airflow/models.py"", line 1334, in run self.handle_failure(e, test_mode, context) File ""/Users/bolke/Documents/dev/airflow_env/lib/python2.7/site-packages/airflow-1.7.2.dev0-py2.7.egg/airflow/models.py"", line 1407, in handle_failure session.merge(self) File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/session.py"", line 1815, in merge File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/session.py"", line 1861, in _merge File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 831, in get File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 864, in _get_impl File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/loading.py"", line 223, in load_on_ident File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 2756, in one File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 2726, in one_or_none File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 2797, in __iter__ File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 2818, in _execute_and_instances File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 2827, in _get_bind_args File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/query.py"", line 2809, in _connection_from_session File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/session.py"", line 966, in connection File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/session.py"", line 971, in _connection_for_bind File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/session.py"", line 382, in _connection_for_bind File ""build/bdist.macosx-10.12-x86_64/egg/sqlalchemy/orm/session.py"", line 276, in _assert_active sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (_mysql_exceptions.OperationalError) (1213, 'Deadlock found when trying to get lock; try restarting transaction') [SQL: u'INSERT INTO xcom (`key`, value, timestamp, execution_date, task_id, dag_id) VALUES (%s, %s, now(), %s, %s, %s)'] [parameters: (u'return_value', '\x80\x02}q\x00(U\x06statusq\x01\x89U\ntimeperiodq\x02cdatetime\ndatetime\nq\x03U\n\x07\xe1\x01\x06\x13\x00\x00\x00\x00\x00q\x04\x85q\x05Rq\x06U\x0bdata_streamq\x07U\x08stream26q\x08u.', datetime.datetime(2017, 1, 6, 20, 0), 'poll_stream26', 'xcom_test')] {code}"
11,AIRFLOW-747,AIRFLOW,1484155872000,1484688596000,Bug,Closed,Blocker,1,1001,"retry_delay not honored In Airflow 1.8 alpha 2, using LocalExecutor, DAGs do not seem to honor the retry_delay parameter, i.e. the retries happen immediately one after the other without waiting the specific retry_delay time. However, the number of retries is honored. I am testing with the following code: from airflow import DAG from airflow.operators.bash_operator import BashOperator from datetime import datetime, timedelta default_args = { 'owner': 'airflow', 'depends_on_past': False, 'start_date': datetime(2016, 10, 5, 19), 'end_date': datetime(2016, 10, 6, 19), 'email': ['airflow@airflow.com'], 'email_on_failure': False, 'email_on_retry': False, 'retries': 10, 'retry_delay': timedelta(0, 500) } dag = DAG('test_retry_handling_job', default_args=default_args, schedule_interval='@once') task1 = BashOperator( task_id='test_retry_handling_op1', bash_command='exit 1', dag=dag) task2 = BashOperator( task_id='test_retry_handling_op2', bash_command='exit 1', dag=dag) task2.set_upstream(task1)"
12,AIRFLOW-778,AIRFLOW,1484943262000,1486061708000,Bug,Resolved,Blocker,1,267,Metastore Partition Sensor Broken MetastorePartitionSensor always throws an exception on initialization due to 72cc8b3006576153aa30d27643807b4ae5dfb593 . Looks like the tests for this are only run if an explicit flag is set which is how this got past CI. cc [~xuanji]
13,AIRFLOW-803,AIRFLOW,1485341396000,1489525140000,Bug,Resolved,Blocker,1,461,"Manual triggered dags are not running After cgroups+impersonation was added the task_instances for manually created dag_runs are not executed anymore. This is due to the fact the task_instance table is now joined against running dag_runs with a 'scheduled' run_id. This change is however not required, as task_instances will only be in 'scheduled' state when they are send to the executore. Tasks from dag_runs in failed state will not be scheduled by contract."
14,AIRFLOW-821,AIRFLOW,1485857944000,1487511153000,Bug,Resolved,Blocker,1,237,Scheduler dagbag importing not Py3 compatible Function {{update_import_errors}} in scheduler (https://github.com/apache/incubator-airflow/blob/master/airflow/jobs.py#L694) in not Py3 compatible (using {{iteritems}} instead of {{items}}).
15,AIRFLOW-844,AIRFLOW,1486421662000,1486500622000,Bug,Resolved,Blocker,1,159,"CgroupTaskRunner does not create cgroups correctly Right now os.mkdir is used to create cgroups which is incorrect, instead the cgroups library should be used."
16,AIRFLOW-846,AIRFLOW,1486467795000,1489524613000,Task,Closed,Blocker,1,536,"Release schedule, latest tag is too old To my understanding, there is no clear point about the release schedule of the project. The latest tag is 1.7.1.3 from June 2016, which is not well suited for production now days. For example, the latest available release is still affected by AIRFLOW-178 which means that we have to patch the sources on production to work with ZIP files. Could you please share your thoughts and position on the release planning of the project ? Would it be possible to get a newer tag sometimes soon ? Thank you"
17,AIRFLOW-847,AIRFLOW,1486475103000,1558131912000,Bug,Resolved,Blocker,1,220,Xcoms are not passed into SubDAG It's not possible to do a xcom_pull within a subdag None of the following seems to be working: * As templated var in SubDagoperator * As var in SubDagoperator * From within Subdag-factory
18,AIRFLOW-856,AIRFLOW,1486675763000,1486732738000,Bug,Resolved,Blocker,1,316,"Execution_date is always set to None in local_client API def trigger_dag(self, dag_id, run_id=None, conf=None, execution_date=None): dr = trigger_dag.trigger_dag(dag_id=dag_id, run_id=run_id, conf=conf, execution_date=None) return ""Created {}"".format(dr) is the code in local_client. This sets execution_date to None"
19,AIRFLOW-893,AIRFLOW,1487798258000,1487886741000,Bug,Resolved,Blocker,1,259,"Webservers crash when a DAG doesn't have a start date set This commit introduced a bug: [AIRFLOW-510] Filter Paused Dags, show Last Run & Trigger Dag 7c94d81c390881643f94d5e3d7d6fb351a445b72 Where webservers will crash if a DAG does not have a start date set."
20,AIRFLOW-894,AIRFLOW,1487865446000,1516027157000,Bug,Closed,Blocker,1,1158,"Trigger Rules not functioning Code below fails to schedule the join task. This includes with trigger rules for all_done, and one_success. It seems to only occur when dynamically generating tasks. from airflow import DAG from airflow.operators import PythonOperator, BranchPythonOperator, DummyOperator from datetime import datetime, timedelta from datetime import datetime from slackclient import SlackClient default_args = { 'owner': 'analytics', 'depends_on_past': False, #'start_date': sixty_days_ago, 'start_date': datetime(2017, 2, 22), 'retries': 0 # 'retry_delay': timedelta(seconds=30), } dag = DAG( 'Valet_Data', default_args=default_args, schedule_interval='*/5 * * * *', dagrun_timeout=timedelta(seconds=60)) def valet_function(locdata, ds, **kwargs): if locdata == 'D': print(intentionalFail) join = DummyOperator( task_id='join', trigger_rule='all_done', dag=dag ) list = ['A','B','C','D','E','F','G','H','I','J','Z'] for l in list: task = PythonOperator( task_id='{0}_PANTS'.format(l), provide_context=True, python_callable=valet_function, op_kwargs={'locdata': l}, # on_failure_callback=on_failure, # on_success_callback=on_success, dag=dag, )"
21,AIRFLOW-897,AIRFLOW,1487885310000,1487975374000,Bug,Closed,Blocker,1,320,"Dagruns get marked as failed as soon as one root task fails In 1.7.1, all root tasks must have failed in order for a dagrun to fail, in 1.8.0 a single root task failure will fail a dagrun and prevent all other tasks in the DAG from running which is not logical behavior and a regression from 1.7.1. [~bolke][~criccomini]"
22,AIRFLOW-910,AIRFLOW,1488047085000,1569858390000,Sub-task,Resolved,Blocker,1,167,Parallelize dag runs in backfills Currently dag runs are executed sequentially while backfilling. This is a regression and slows down the processing off tasks. [~aoen]
23,AIRFLOW-921,AIRFLOW,1488223549000,1489380318000,Task,Resolved,Blocker,1,600,"1.8.0rc Issues These are the pending issues for the Airflow 1.8.0 release: Blockers: [~bolke] please merge into the next RC and then remove from the list the sub-tasks linked in this JIRA Other Issues: - High DB Load (~8x more than 1.7) - We are still investigating but it's probably not a blocker for the release - (Theories: Might need execution_date index on dag_run (based on slow process list) OR it might be this query which is long running SELECT union_ti.dag_id AS union_ti_dag_id, union_ti.state AS union_ti_state, count( *) AS count_1 FR)) - Front page loading time is a lot slower [~bolke]"
24,AIRFLOW-932,AIRFLOW,1488394470000,1489380308000,Sub-task,Resolved,Blocker,1,90,Backfills delete existing task instances and mark them as removed I'm still investigating.
25,AIRFLOW-934,AIRFLOW,1488425529000,1489519643000,Bug,Resolved,Blocker,1,2440,"airflow delayed the task to start we have a complex DAG which includes many tasks. but recently we found some tasks start delayed. for instance: start_task(which will start at 00:00) --> create_cluster(will finished at 00:11) --> wait_task(start at 00:16) , note: 1. wait_task only has one upstream that is create_cluster 2. the server that the airflow hosts has enough memory, and celeryd_concurrency is 20. below is the log of wait_task: [2017-03-02 00:16:39,602] {models.py:124} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:16:39,603] {models.py:197} INFO - Importing /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:16:39,613] {models.py:284} INFO - Loaded DAG <DAG: etl_prod> [2017-03-02 00:16:40,333] {models.py:124} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:16:40,333] {models.py:197} INFO - Importing /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:16:40,345] {models.py:284} INFO - Loaded DAG <DAG: etl_prod> [2017-03-02 00:16:40,373] {models.py:936} INFO - -------------------------------------------------------------------------------- New run starting @2017-03-02T00:16:40.369560 -------------------------------------------------------------------------------- [2017-03-02 00:16:40,402] {models.py:951} INFO - Queuing into pool None [2017-03-02 00:22:31,161] {models.py:124} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:22:31,162] {models.py:197} INFO - Importing /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:22:31,172] {models.py:284} INFO - Loaded DAG <DAG: etl_prod> [2017-03-02 00:22:31,863] {models.py:124} INFO - Filling up the DagBag from /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:22:31,863] {models.py:197} INFO - Importing /home/ubuntu/airflow/dags/etl_prod/etl_prod.py [2017-03-02 00:22:31,874] {models.py:284} INFO - Loaded DAG <DAG: etl_prod> [2017-03-02 00:22:31,901] {models.py:936} INFO - -------------------------------------------------------------------------------- New run starting @2017-03-02T00:22:31.897547 -------------------------------------------------------------------------------- [2017-03-02 00:22:31,911] {models.py:974} INFO - Executing <Task(BashOperator): wait_mins> on 2017-03-01 00:00:00 [2017-03-02 00:22:31,922] {bash_operator.py:52} INFO - tmp dir root location: /tmp"
26,AIRFLOW-968,AIRFLOW,1489180243000,1556702180000,Bug,Closed,Blocker,1,298,"TravisCI builds in master are failing for Python 2.7 Last good build on master: https://travis-ci.org/apache/incubator-airflow/builds/204780659 First failing build on master: https://travis-ci.org/apache/incubator-airflow/builds/205138766 Python 3.4 builds seem fine, Python 2.7 builds are failing."
27,AIRFLOW-1000,AIRFLOW,1489779310000,1492445369000,Task,Closed,Blocker,1,478,"Rebrand to Apache Airflow instead of Airflow Apache requires branding in the form of ""Apache Airflow"" instead of just ""Airflow"". We should figure out a way to rebrand to ""Apache Airflow"" while having an upgrade path as smooth as possible for our users. This could mean that we first release side-by-side: airflow-1.8.1-apache.incubating apache-airflow-1.8.1-incubating It seems that pip does support some kind of packaging that helps with this (see for example Apache Libcloud)."
28,AIRFLOW-1001,AIRFLOW,1489782787000,1535984422000,Bug,Closed,Blocker,1,1990,"Landing Time shows ""unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType'"" on example_subdag_operator Sample DAG example_subdag_operator shows below Oops page on ""Landing Times"" tab {noformat} ------------------------------------------------------------------------------- Traceback (most recent call last): File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask/app.py"", line 1988, in wsgi_app response = self.full_dispatch_request() File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask/app.py"", line 1641, in full_dispatch_request rv = self.handle_user_exception(e) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask/app.py"", line 1544, in handle_user_exception reraise(exc_type, exc_value, tb) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask/app.py"", line 1639, in full_dispatch_request rv = self.dispatch_request() File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask/app.py"", line 1625, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask_admin/base.py"", line 69, in inner return self._run_view(f, *args, **kwargs) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask_admin/base.py"", line 368, in _run_view return fn(self, *args, **kwargs) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/flask_login.py"", line 755, in decorated_view return func(*args, **kwargs) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/airflow/www/utils.py"", line 125, in wrapper return f(*args, **kwargs) File ""/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/airflow/www/views.py"", line 1560, in landing_times secs = (ti.end_date - ts).total_seconds() TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType' {noformat} http://somehost:18111/admin/airflow/landing_times?root=&days=30&dag_id=example_subdag_operator"
29,AIRFLOW-1011,AIRFLOW,1489933675000,1558131584000,Bug,Resolved,Blocker,1,426,"Fix bug in BackfillJob._execute() for SubDAGs The attached test SubDAG is not executed when the parent DAG is triggered manually. Attached is a simple test DAG that exhibits the issue along with screenshots showing the UI differences between v1.8 and v1.7.1.3. Note that if the DAG is run via backfill from command line (e.g. ""airflow backfill Test_SubDAG -s 2017-03-18 -e 2017-03-18"") the task instances show up successfully."
30,AIRFLOW-1018,AIRFLOW,1490049741000,1580461132000,Bug,Resolved,Blocker,1,409,"Scheduler DAG processes can not log to stdout Each DAG has its own log file for the scheduler and we can specify the directory with child_process_log_directory param. Unfortunately we can not change device / by specifying /dev/stdout for example. That is very useful when we execute Airflow in a container. When we specify /dev/stdout it raises: ""OSError: [Errno 20] Not a directory: '/dev/stdout/2017-03-19'"""
31,AIRFLOW-1033,AIRFLOW,1490286084000,1491480235000,Bug,Resolved,Blocker,1,2377,"TypeError: can't compare datetime.datetime to NoneType in prev_dagrun_dep.py Dear, When starting a specific new dag we get the following error: [2017-03-23 16:51:16,354] {jobs.py:354} DagFileProcessor908 ERROR - Got an exception! Propagating... Traceback (most recent call last): File ""/usr/lib/python2.7/site-packages/airflow/jobs.py"", line 346, in helper pickle_dags) File ""/usr/lib/python2.7/site-packages/airflow/utils/db.py"", line 53, in wrapper result = func(*args, **kwargs) File ""/usr/lib/python2.7/site-packages/airflow/jobs.py"", line 1581, in process_file self._process_dags(dagbag, dags, ti_keys_to_schedule) File ""/usr/lib/python2.7/site-packages/airflow/jobs.py"", line 1174, in _process_dags self._process_task_instances(dag, tis_out) File ""/usr/lib/python2.7/site-packages/airflow/jobs.py"", line 905, in _process_task_instances session=session): File ""/usr/lib/python2.7/site-packages/airflow/utils/db.py"", line 53, in wrapper result = func(*args, **kwargs) File ""/usr/lib/python2.7/site-packages/airflow/models.py"", line 1116, in are_dependencies_met session=session): File ""/usr/lib/python2.7/site-packages/airflow/models.py"", line 1140, in get_failed_dep_statuses dep_context): File ""/usr/lib/python2.7/site-packages/airflow/ti_deps/deps/base_ti_dep.py"", line 94, in get_dep_statuses for dep_status in self._get_dep_statuses(ti, session, dep_context): File ""/usr/lib/python2.7/site-packages/airflow/ti_deps/deps/prev_dagrun_dep.py"", line 47, in _get_dep_statuses if dag.previous_schedule(ti.execution_date) < ti.task.start_date: TypeError: can't compare datetime.datetime to NoneType I have added some debug code to the file 'prev_dagrun_dep.py: dag = ti.task.dag print 'Start dates:' print 'previous_exection_date: %s'%(dag.previous_schedule(ti.execution_date)) print 'current start date: %s'%(ti.task.start_date) if dag.catchup: if dag.previous_schedule(ti.execution_date) < ti.task.start_date: And this is the output I get: Start dates: previous_exection_date: None current start date: 2017-03-19 00:00:00 I think it is normall that the previous_exection_date is null, since it is the first time this dag is being run. But why is the start_date of the dag important, and not the start date of the run? I have the feeling the cause is the 'schedule_interval', which is set to None. Please find an example and it's log file as an attachment to this mail. Bert"
32,AIRFLOW-1050,AIRFLOW,1490674660000,1491544846000,Bug,Resolved,Blocker,1,1336,"Retries ignored - regression SubDag fails when first operator fails, despite the fact it's configured for retries. Information in UI afterwards are also incorrect. From SubDag prospective it's still {{running}} with operator marked as {{up_for_retry}}, from main DAG prospective, whole run is marked as {{failed}} same as SubDag. See attached screenshots. Latest not affected version is RC4 (310fb58). I tested RC5, 1.8.0 with LocalExecutor and CeleryExecutor. Example code: {code} from datetime import datetime, timedelta from airflow.models import DAG from airflow.operators.bash_operator import BashOperator from airflow.operators.python_operator import PythonOperator from airflow.operators.subdag_operator import SubDagOperator args = { ""start_date"": datetime.today(), } dag = DAG( dag_id=""main"", default_args=args, dagrun_timeout=timedelta(minutes=60), schedule_interval=None, max_active_runs=1 ) sub_dag = DAG( dag_id=""main.test"", default_args=args, schedule_interval=None, ) op = BashOperator( task_id=""first"", dag=sub_dag, bash_command=""echo 1"" ) def throw_error(): raise RuntimeError() op2 = PythonOperator( task_id=""second"", dag=sub_dag, python_callable=throw_error, retries=3, retry_delay=timedelta(0, 20) ) op >> op2 prepare_environment = SubDagOperator( task_id='test', subdag=sub_dag, default_args=args, dag=dag, ) {code}"
33,AIRFLOW-1103,AIRFLOW,1491970176000,1516027138000,Task,Closed,Blocker,1,406,How we can check our developer programmes are pick which environment variables Hi I have updated environment variable .bashrc .profile but those are not picking up from programmes which is running from airflow what is the command to check what are the environment variables are picking by airflow ps eww 22559 can you guid me on this command or any other tool to find which environment variables are taking
34,AIRFLOW-1121,AIRFLOW,1492551627000,1497401870000,Bug,Resolved,Blocker,1,1167,"airflow webserver --pid no longer write out pid file! I've run into a regression with the webserver. It looks like the --pid argument is no longer honored in 1.8.1. The pid file is not being written out! As a result, watchdog processes like monitd, which watch the processes mentioned in the pid file, keep trying to spawn webservers because the pid files are not being written. HISTTIMEFORMAT=""%d/%m/%y %T "" PYTHONPATH=/usr/local/agari/ep-pipeline/production/current/analysis/cluster/:/usr/local/agari/ep-pipeline/production/current/analysis/lookups/ TMP=/data/tmp AIRFLOW_HOME=/data/airflow PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin airflow webserver -p 8080 --pid /data/airflow/pids/airflow-webserver.pid The Patch that might have broken this is https://github.com/apache/incubator-airflow/commit/a9b20a04 If I include -D, things work: airflow webserver -D --pid ~/this.pid sid-as-mbp:~ siddharth$ ls -lrt *pid -rw-r--r-- 1 siddharth staff 5 Apr 18 14:37 this-monitor.pid -rw-r--r-- 1 siddharth staff 5 Apr 18 14:37 this.pid sid-as-mbp:~ siddharth$ cat *pid 8732 8735 However, this doesn't help me as I don't want to run with -D. cc [~sekikn] [~criccomini]"
35,AIRFLOW-1124,AIRFLOW,1492599475000,1503954859000,Bug,Resolved,Blocker,1,166,"Do not set all task instances to scheduled on backfill Backfills are supposed to fill in the gaps, but in 1.8.0 we set all tasks to scheduled, so they will run again."
36,AIRFLOW-1127,AIRFLOW,1492631470000,1494351336000,Improvement,Closed,Blocker,1,497,"Move license notices to LICENSE instead of NOTICE For all the bundled files with different licenses (MIT, BSD, etc), the full texts of these licenses should be in the source tarball preferably at the end of the LICENSE file. webgl-2d needs to be called out as MIT license. Are all the entries in the NOTICE file required or do they just need to be in the LICENSE file? Any additions to the NOTICE have downstream repercussions as they need to be propagated down by any other project using airflow."
37,AIRFLOW-1132,AIRFLOW,1492709647000,1492709880000,Bug,Closed,Blocker,1,1570,"Clear DAG via UI causes exception When I try to clear some of my failed tasks via the UI, I get: {noformat} Traceback (most recent call last): File ""/usr/lib64/python2.7/site-packages/flask/app.py"", line 1988, in wsgi_app response = self.full_dispatch_request() File ""/usr/lib64/python2.7/site-packages/flask/app.py"", line 1641, in full_dispatch_request rv = self.handle_user_exception(e) File ""/usr/lib64/python2.7/site-packages/flask/app.py"", line 1544, in handle_user_exception reraise(exc_type, exc_value, tb) File ""/usr/lib64/python2.7/site-packages/flask/app.py"", line 1639, in full_dispatch_request rv = self.dispatch_request() File ""/usr/lib64/python2.7/site-packages/flask/app.py"", line 1625, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File ""/usr/lib64/python2.7/site-packages/flask_admin/base.py"", line 69, in inner return self._run_view(f, *args, **kwargs) File ""/usr/lib64/python2.7/site-packages/flask_admin/base.py"", line 368, in _run_view return fn(self, *args, **kwargs) File ""/usr/lib64/python2.7/site-packages/flask_login.py"", line 758, in decorated_view return func(*args, **kwargs) File ""/usr/lib/python2.7/site-packages/airflow/www/utils.py"", line 125, in wrapper return f(*args, **kwargs) File ""/usr/lib/python2.7/site-packages/airflow/www/utils.py"", line 172, in wrapper return f(*args, **kwargs) File ""/usr/lib/python2.7/site-packages/airflow/www/views.py"", line 1013, in clear dag = dag.sub_dag( AttributeError: 'NoneType' object has no attribute 'sub_dag' {noformat} These are failed DAGs with a failed task."
38,AIRFLOW-1138,AIRFLOW,1492787582000,1562254362000,Task,Resolved,Blocker,1,152,Add licenses to files in scripts directory These two files need license headers: modified: scripts/ci/requirements.txt modified: scripts/systemd/airflow
39,AIRFLOW-1142,AIRFLOW,1493079256000,1558131588000,Bug,Resolved,Blocker,1,588,"SubDAG Tasks Not Executed Even Though All Dependencies Met Testing on 1.8.1rc1, we noticed that tasks in subdags were not getting executed even though all dependencies had been met. We were able to create a simple test DAG that re-creates the issue. Attached is a test DAG, the log file of the subdag operator that shows it fails to run even though dependencies are met, and screenshots of what the UI looks like. This is definitely a regression as we have many similarly constructed DAGs that have been running successfully on a pre-v1.8 version (a fork of 1.7.1.3+master) for some time."
40,AIRFLOW-1178,AIRFLOW,1494178685000,1537533752000,Bug,Closed,Blocker,1,1234,"@once may run more than one time My DAG is running second (2nd) time although it is declared as @once. Here's DAG definition : {noformat} main_dag = DAG( dag_id = 'Test-DAG-1', default_args = default_args, # dafeult operators' arguments - see above user_defined_macros = dag_macros, # I do not get different between ## params = dag_macros, # user_defined_macros and params # start_date = datetime.now(), # or e.g. datetime(2015, 6, 1) # 'end_date' = datetime(2016, 1, 1), catchup = True, # Perform scheduler catchup (or only run latest)? # - defaults to True schedule_interval = '@once', # '@once'=None? # doesn't create multiple dag runs automatically concurrency = 3, # task instances allowed to run concurrently max_active_runs = 1, # only one DAG run at a time dagrun_timeout = timedelta(days=4), # no way this dag should ran for 4 days orientation = 'TB', # default graph view ) {noformat} As a workaround for AIRFLOW-1013 I changed catchup from False to True. Suggested on dev list. It ""worked around"" AIRFLOW-1013 execution, but screwed @once logic - the DAG got scheduled twice (!) which is a no-go for us. The DAG actually has to run not more than 1 time. IMO, catchup=True should be explicitly disallowed for @once schedule."
41,AIRFLOW-1290,AIRFLOW,1496868784000,1496936058000,Bug,Resolved,Blocker,1,330,"Change docs author from ""Maxime Beauchemin"" to ""Apache Airflow"" In `docs/conf.py`, the author of the docs is set to ""Maxime Beauchemin"" who was the original author of the docs, but since then the whole community has taken over authoring the Airflow documentation. Change all references from ""Maxime Beauchemin"" to ""Apache Airflow"""
42,AIRFLOW-1291,AIRFLOW,1496875106000,1505332197000,Bug,Resolved,Blocker,1,49,Update NOTICE and LICENSE files to meet ASF specs
43,AIRFLOW-1294,AIRFLOW,1496906049000,1497367452000,Bug,Resolved,Blocker,1,302,"Backfills can loose tasks to execute due to tasks setting themselves to NONE In the backfills we can loose tasks to execute due to a task setting its own state to NONE if concurrency limits are reached, this makes them fall outside of the scope the backfill is managing hence they will not be executed."
44,AIRFLOW-1296,AIRFLOW,1496967081000,1534855855000,Bug,Resolved,Blocker,1,1963,"DAGs using operators involving cascading skipped tasks fail prematurely So this is basically the same issue as AIRFLOW-872 and AIRFLOW-719. A workaround had fixed this (https://github.com/apache/incubator-airflow/pull/2125), but was later reverted (https://github.com/apache/incubator-airflow/pull/2195). I totally agree with the reason for reverting, but I still think this is an issue. The issue is related to any operators that involves cascading skipped tasks, like ShortCircuitOperator or LatestOnlyOperator. These operators mark only their *direct* downstream task as SKIPPED, but additional downstream tasks from that skipped task is left up to the scheduler to cascade the SKIPPED state (see latest only op docs about this expected behavior https://airflow.incubator.apache.org/concepts.html#latest-run-only). However, instead the scheduler marks the DAG run as FAILED prematurely before the DAG has a chance to skip all downstream tasks. This example DAG should reproduce the issue: https://gist.github.com/dhuang/61d38fb001c3a917edf4817bb0c915f9. Expected result: DAG succeeds with tasks - latest_only (success) -> dummy1 (skipped) -> dummy2 (skipped) -> dummy3 (skipped) Actual result: DAG fails with tasks - latest_only (success) -> dummy1 (skipped) -> dummy2 (none) -> dummy3 (none) I believe the results I'm seeing are because of this deadlock prevention logic, https://github.com/apache/incubator-airflow/blob/1.8.1/airflow/models.py#L4182. While that actual result shown above _could_ mean a deadlock, in this case it shouldn't be. Since this {{update_state}} logic is reached first in each scheduler run, dummy2/dummy3 don't get a chance to cascade the SKIPPED state. Commenting out that block gives me the results I expect. [~bolke] I know you spent awhile trying to reproduce my issue and weren't able to, but I'm still hitting this on a fresh environment, default configs, sqlite/mysql dbs, local/sequential/celery executors, and 1.8.1/master."
45,AIRFLOW-1482,AIRFLOW,1501684834000,1564723828000,Bug,Open,Blocker,1,4596,"Error when try to backfill the example_trigger_controller_dag Hello, Running a backfill command for the {noformat}example_trigger_controller_dag{noformat} example dag, result in the failed task {noformat}test_trigger_dagrun{noformat} It seems to me that the problem comes from the TriggerDagRunOperator in the example_trigger_controller_dag ? Backfill command: {noformat}airflow backfill -s 2017-07-10 -e 2017-07-13 --pool backfill example_trigger_controller_dag{noformat} Tested in 1.8.1 and 1.8.2rc1 Here is the output log from the backfill command : {noformat} [2017-08-02 13:53:00,844] {__init__.py:57} INFO - Using executor CeleryExecutor [2017-08-02 13:53:00,888] {driver.py:120} INFO - Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt [2017-08-02 13:53:00,902] {driver.py:120} INFO - Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt /var/lib/airflow/local/lib/python2.7/site-packages/airflow/www/app.py:23: FlaskWTFDeprecationWarning: ""flask_wtf.CsrfProtect"" has been renamed to ""CSRFProtect"" and will be removed in 1.0. csrf = CsrfProtect() [2017-08-02 13:53:01,033] {models.py:168} INFO - Filling up the DagBag from /var/lib/airflow/dags [2017-08-02 13:53:01,332] {models.py:1128} INFO - Dependencies all met for <TaskInstance: example_trigger_controller_dag.test_trigger_dagrun 2017-07-10 00:00:00 [scheduled]> [2017-08-02 13:53:01,337] {base_executor.py:50} INFO - Adding to queue: airflow run example_trigger_controller_dag test_trigger_dagrun 2017-07-10T00:00:00 --pickle 1 --local --pool backfill [2017-08-02 13:53:06,267] {celery_executor.py:81} INFO - [celery] queuing (u'example_trigger_controller_dag', u'test_trigger_dagrun', datetime.datetime(2017, 7, 10, 0, 0)) through celery, queue=default [2017-08-02 13:53:06,330] {models.py:4164} INFO - Updating state for <DagRun example_trigger_controller_dag @ 2017-07-10 00:00:00: backfill_2017-07-10T00:00:00, externally triggered: False> considering 1 task(s) [2017-08-02 13:53:06,334] {jobs.py:2020} INFO - [backfill progress] | finished run 0 of 1 | tasks waiting: 0 | succeeded: 0 | kicked_off: 1 | failed: 0 | skipped: 0 | deadlocked: 0 | not ready: 0 [2017-08-02 13:53:11,273] {jobs.py:1743} ERROR - Executor reports task instance <TaskInstance: example_trigger_controller_dag.test_trigger_dagrun 2017-07-10 00:00:00 [queued]> finished (failed) although the task says its queued. Was the task killed externally? [2017-08-02 13:53:11,273] {models.py:1433} ERROR - Executor reports task instance <TaskInstance: example_trigger_controller_dag.test_trigger_dagrun 2017-07-10 00:00:00 [queued]> finished (failed) although the task says its queued. Was the task killed externally? None [2017-08-02 13:53:11,273] {models.py:1457} INFO - Marking task as FAILED. [2017-08-02 13:53:11,279] {models.py:1478} ERROR - Executor reports task instance <TaskInstance: example_trigger_controller_dag.test_trigger_dagrun 2017-07-10 00:00:00 [queued]> finished (failed) although the task says its queued. Was the task killed externally? [2017-08-02 13:53:11,281] {jobs.py:1694} ERROR - Task instance <TaskInstance: example_trigger_controller_dag.test_trigger_dagrun 2017-07-10 00:00:00 [failed]> failed [2017-08-02 13:53:11,283] {models.py:4164} INFO - Updating state for <DagRun example_trigger_controller_dag @ 2017-07-10 00:00:00: backfill_2017-07-10T00:00:00, externally triggered: False> considering 1 task(s) [2017-08-02 13:53:11,285] {models.py:4204} INFO - Marking run <DagRun example_trigger_controller_dag @ 2017-07-10 00:00:00: backfill_2017-07-10T00:00:00, externally triggered: False> failed [2017-08-02 13:53:11,298] {jobs.py:2020} INFO - [backfill progress] | finished run 1 of 1 | tasks waiting: 0 | succeeded: 0 | kicked_off: 0 | failed: 1 | skipped: 0 | deadlocked: 0 | not ready: 0 Traceback (most recent call last): File ""/var/lib/airflow/bin/airflow"", line 28, in <module> args.func(args) File ""/var/lib/airflow/local/lib/python2.7/site-packages/airflow/bin/cli.py"", line 167, in backfill pool=args.pool) File ""/var/lib/airflow/local/lib/python2.7/site-packages/airflow/models.py"", line 3373, in run job.run() File ""/var/lib/airflow/local/lib/python2.7/site-packages/airflow/jobs.py"", line 201, in run self._execute() File ""/var/lib/airflow/local/lib/python2.7/site-packages/airflow/jobs.py"", line 2063, in _execute raise AirflowException(err) airflow.exceptions.AirflowException: --------------------------------------------------- Some task instances failed: set([(u'example_trigger_controller_dag', u'test_trigger_dagrun', datetime.datetime(2017, 7, 10, 0, 0))]) {noformat}"
46,AIRFLOW-1494,AIRFLOW,1502177433000,1535980836000,Bug,Resolved,Blocker,1,12327,"backfill job failed because new retry comes out when a valid job is running I have a spark job, wrapped in a BASH command to run. From fail log, i found airflow try to rerun the job while the job is running. Then a series strange things happened. My job finally failed. Logs Below: [2017-08-07 23:24:35,903] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:35,903] {bash_operator.py:94} INFO - 17/08/07 23:24:35 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:36,904] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:36,904] {bash_operator.py:94} INFO - 17/08/07 23:24:36 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:37,905] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:37,904] {bash_operator.py:94} INFO - 17/08/07 23:24:37 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:38,906] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:38,906] {bash_operator.py:94} INFO - 17/08/07 23:24:38 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:38,947] {cli.py:391} INFO - Loading pickle id 148 [2017-08-07 23:24:39,020] {base_task_runner.py:112} INFO - Running: ['bash', '-c', u'airflow run generated_daily submit_operator 2017-08-05T00:00:00 --pickle 148 --job_id 15372 --raw'] [2017-08-07 23:24:39,426] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,426] {__init__.py:57} INFO - Using executor CeleryExecutor [2017-08-07 23:24:39,495] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,494] {driver.py:120} INFO - Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt [2017-08-07 23:24:39,519] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,519] {driver.py:120} INFO - Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt [2017-08-07 23:24:39,710] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,710] {cli.py:391} INFO - Loading pickle id 148 [2017-08-07 23:24:39,772] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,772] {models.py:1120} INFO - Dependencies not met for <TaskInstance: generated_daily.submit_operator 2017-08-05 00:00:00 [running]>, dependency 'Task Instance Not Already Running' FAILED: Task is already running, it started on 2017-08-07 20:55:12.727910. [2017-08-07 23:24:39,777] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,777] {models.py:1120} INFO - Dependencies not met for <TaskInstance: generated_daily.submit_operator 2017-08-05 00:00:00 [running]>, dependency 'Task Instance State' FAILED: Task is in the 'running' state which is not a valid state for execution. The task must be cleared in order to be run. [2017-08-07 23:24:39,907] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:39,907] {bash_operator.py:94} INFO - 17/08/07 23:24:39 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:40,908] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:40,908] {bash_operator.py:94} INFO - 17/08/07 23:24:40 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:41,909] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:41,909] {bash_operator.py:94} INFO - 17/08/07 23:24:41 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:42,911] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:42,910] {bash_operator.py:94} INFO - 17/08/07 23:24:42 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:43,912] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:43,912] {bash_operator.py:94} INFO - 17/08/07 23:24:43 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:44,120] {jobs.py:2148} WARNING - Recorded pid 116446 is not a descendant of the current pid 33416 [2017-08-07 23:24:44,914] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:44,913] {bash_operator.py:94} INFO - 17/08/07 23:24:44 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:45,914] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:45,914] {bash_operator.py:94} INFO - 17/08/07 23:24:45 INFO yarn.Client: Application report for application_1498090868254_911911 (state: RUNNING) [2017-08-07 23:24:46,032] {jobs.py:2155} WARNING - State of this instance has been externally set to up_for_retry. Taking the poison pill. So long. [2017-08-07 23:24:46,081] {helpers.py:220} WARNING - Terminating descendant processes of ['/usr/bin/python /usr/local/bin/airflow run generated_daily submit_operator 2017-08-05T00:00:00 --pickle 148 --job_id 15015 --raw'] PID: 116446 [2017-08-07 23:24:46,081] {helpers.py:224} WARNING - Terminating descendant process ['bash', '/tmp/airflowtmpCFeIBn/submit_operatorGbO01R'] PID: 116496 [2017-08-07 23:24:46,087] {helpers.py:224} WARNING - Terminating descendant process ['/bin/sh', '/mnt/data/firework-0.2.0/bin/spark-submit', '--spark-version', '1.6.2', '--master', 'yarn-cluster', '--num-executors', '128', '--class', 'com.hulu.reco.metrics.middlelayer.BatchApplication', '--conf', 'spark.date=20170805', '--conf', 'spark.yarn.maxAppAttempts=1', '--conf', 'spark.driver.memory=8g', '--conf', 'spark.executor.memory=36g', '--conf', 'spark.executor.cores=8', '--conf', 'spark.user.javahome.enabled=true', '--conf', 'spark.user.javahome.path=/usr/lib/jvm/hulu-oracle-jdk8', '--conf', 'spark.output=hdfs://warehousestore/user/pcdm/generated_prod/20170805', '--queue', 'spark', '/home/deploy/middlelayer-1.0-SNAPSHOT-jar-with-dependencies.jar'] PID: 116498 [2017-08-07 23:24:46,091] {helpers.py:224} WARNING - Terminating descendant process ['/usr/java/jdk8/jdk1.8.0_92-1//bin/java', '-cp', '/mnt/data/firework-0.2.0/.firework_cache/spark/els/1.6.2/b72e04b6120cd0a431aae3195db97706/conf/:/mnt/data/firework-0.2.0/.firework_cache/spark/els/1.6.2/b72e04b6120cd0a431aae3195db97706/assembly/target/scala-2.10/spark-assembly-1.6.2-hadoop2.6.0-cdh5.7.3-201612201803.jar:/mnt/data/firework-0.2.0/.firework_cache/spark/els/1.6.2/b72e04b6120cd0a431aae3195db97706/lib_managed/jars/datanucleus-rdbms-3.2.9.jar:/mnt/data/firework-0.2.0/.firework_cache/spark/els/1.6.2/b72e04b6120cd0a431aae3195db97706/lib_managed/jars/datanucleus-core-3.2.10.jar:/mnt/data/firework-0.2.0/.firework_cache/spark/els/1.6.2/b72e04b6120cd0a431aae3195db97706/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar:/mnt/data/firework-0.2.0/.firework_cache/spark/els/1.6.2/b72e04b6120cd0a431aae3195db97706/hadoop-conf/', 'org.apache.spark.deploy.SparkSubmit', '--master', 'yarn-cluster', '--conf', 'spark.executor.memory=36g', '--conf', 'spark.driver.memory=8g', '--conf', 'spark.user.javahome.path=/usr/lib/jvm/hulu-oracle-jdk8', '--conf', 'spark.output=hdfs://warehousestore/user/pcdm/generated_prod/20170805', '--conf', 'spark.yarn.maxAppAttempts=1', '--conf', 'spark.executor.cores=8', '--conf', 'spark.date=20170805', '--conf', 'spark.user.javahome.enabled=true', '--class', 'com.hulu.reco.metrics.middlelayer.BatchApplication', '--num-executors', '128', '--queue', 'spark', '/home/deploy/middlelayer-1.0-SNAPSHOT-jar-with-dependencies.jar'] PID: 116761 [2017-08-07 23:24:46,096] {helpers.py:231} WARNING - Waiting up to 5s for processes to exit... [2017-08-07 23:24:46,099] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:46,099] {bash_operator.py:94} INFO - 17/08/07 23:24:46 INFO util.ShutdownHookManager: Shutdown hook called [2017-08-07 23:24:46,100] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:46,100] {bash_operator.py:94} INFO - 17/08/07 23:24:46 INFO util.ShutdownHookManager: Deleting directory /mnt/data/tmp/spark-b5f3c795-7ea2-4ef1-a47c-2507b0747580 [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:46,118] {bash_operator.py:97} INFO - Command exited with return code -15 [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:46,118] {models.py:1417} ERROR - Bash command failed [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: Traceback (most recent call last): [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/lib/python2.7/dist-packages/airflow/models.py"", line 1374, in run [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: result = task_copy.execute(context=context) [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/lib/python2.7/dist-packages/airflow/operators/bash_operator.py"", line 100, in execute [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: raise AirflowException(""Bash command failed"") [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: AirflowException: Bash command failed [2017-08-07 23:24:46,121] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:46,120] {models.py:1433} INFO - Marking task as UP_FOR_RETRY [2017-08-07 23:24:46,123] {helpers.py:234} WARNING - Done waiting [2017-08-07 23:24:46,131] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:24:46,130] {models.py:1462} ERROR - Bash command failed [2017-08-07 23:24:46,131] {base_task_runner.py:95} INFO - Subtask: Traceback (most recent call last): [2017-08-07 23:24:46,131] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/bin/airflow"", line 28, in <module> [2017-08-07 23:24:46,131] {base_task_runner.py:95} INFO - Subtask: args.func(args) [2017-08-07 23:24:46,131] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/lib/python2.7/dist-packages/airflow/bin/cli.py"", line 422, in run [2017-08-07 23:24:46,132] {base_task_runner.py:95} INFO - Subtask: pool=args.pool, [2017-08-07 23:24:46,132] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/lib/python2.7/dist-packages/airflow/utils/db.py"", line 53, in wrapper [2017-08-07 23:24:46,132] {base_task_runner.py:95} INFO - Subtask: result = func(*args, **kwargs) [2017-08-07 23:24:46,132] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/lib/python2.7/dist-packages/airflow/models.py"", line 1374, in run [2017-08-07 23:24:46,132] {base_task_runner.py:95} INFO - Subtask: result = task_copy.execute(context=context) [2017-08-07 23:24:46,133] {base_task_runner.py:95} INFO - Subtask: File ""/usr/local/lib/python2.7/dist-packages/airflow/operators/bash_operator.py"", line 100, in execute [2017-08-07 23:24:46,133] {base_task_runner.py:95} INFO - Subtask: raise AirflowException(""Bash command failed"") [2017-08-07 23:24:46,133] {base_task_runner.py:95} INFO - Subtask: airflow.exceptions.AirflowException: Bash command failed [2017-08-07 23:24:51,034] {jobs.py:2083} INFO - Task exited with return code 1 [2017-08-07 23:33:27,872] {cli.py:391} INFO - Loading pickle id 148 [2017-08-07 23:33:27,940] {base_task_runner.py:112} INFO - Running: ['bash', '-c', u'airflow run generated_daily submit_operator 2017-08-05T00:00:00 --pickle 148 --job_id 15376 --raw'] [2017-08-07 23:33:28,302] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:33:28,301] {__init__.py:57} INFO - Using executor CeleryExecutor [2017-08-07 23:33:28,359] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:33:28,358] {driver.py:120} INFO - Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt [2017-08-07 23:33:28,378] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:33:28,378] {driver.py:120} INFO - Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt [2017-08-07 23:33:28,543] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:33:28,543] {cli.py:391} INFO - Loading pickle id 148 [2017-08-07 23:33:28,601] {base_task_runner.py:95} INFO - Subtask: [2017-08-07 23:33:28,601] {models.py:1120} INFO - Dependencies not met for <TaskInstance: generated_daily.submit_operator 2017-08-05 00:00:00 [up_for_retry]>, dependency 'Not In Retry Period' FAILED: Task is not ready for retry yet but will be retried automatically. Current date is 2017-08-07T23:33:28.601339 and task will be retried at 2017-08-08T00:24:46.119758. [2017-08-07 23:33:32,954] {jobs.py:2083} INFO - Task exited with return code 0"
47,AIRFLOW-1539,AIRFLOW,1503958220000,1535980907000,Bug,Closed,Blocker,1,1925,"python3 error import Dag Seeing the following error when using python3 (fine with python2) {code} Traceback (most recent call last): File ""/opt/conda/lib/python3.6/site-packages/airflow/models.py"", line 263, in process_file m = imp.load_source(mod_name, filepath) File ""/opt/conda/lib/python3.6/imp.py"", line 172, in load_source module = _load(spec) File ""<frozen importlib._bootstrap>"", line 675, in _load File ""<frozen importlib._bootstrap>"", line 655, in _load_unlocked File ""<frozen importlib._bootstrap_external>"", line 678, in exec_module File ""<frozen importlib._bootstrap>"", line 205, in _call_with_frames_removed File ""/root/airflow/dags/LoadS3ToHiveTest.py"", line 2, in <module> from LoadS3ToHive import default_args, download_s3_to_hdfs_templated_command, generate_download_s3_to_hdfs_task, \ File ""/root/airflow/dags/LoadS3ToHive.py"", line 74, in <module> globals()[task_name] = DAG(task_name, default_args=default_args, schedule_interval=None) File ""/opt/conda/lib/python3.6/site-packages/airflow/models.py"", line 2664, in __init__ self.fileloc = inspect.getsourcefile(inspect.stack()[1][0]) File ""/opt/conda/lib/python3.6/inspect.py"", line 1465, in stack return getouterframes(sys._getframe(1), context) File ""/opt/conda/lib/python3.6/inspect.py"", line 1442, in getouterframes frameinfo = (frame,) + getframeinfo(frame, context) File ""/opt/conda/lib/python3.6/inspect.py"", line 1411, in getframeinfo filename = getsourcefile(frame) or getfile(frame) File ""/opt/conda/lib/python3.6/inspect.py"", line 666, in getsourcefile if getattr(getmodule(object, filename), '__loader__', None) is not None: File ""/opt/conda/lib/python3.6/inspect.py"", line 703, in getmodule if ismodule(module) and hasattr(module, '__file__'): File ""/opt/conda/lib/python3.6/site-packages/airflow/utils/timeout.py"", line 38, in handle_timeout raise AirflowTaskTimeout(self.error_message) airflow.exceptions.AirflowTaskTimeout: Timeout {code}"
48,AIRFLOW-1641,AIRFLOW,1506332962000,1509112710000,Bug,Closed,Blocker,1,794,"Task gets stuck in queued state Hello, I have one dag with ~20 tasks. The dags runs daily and some tasks can sometime last for hours, depending on the processed data behind. There are some interactions with AWS and a remote DB. I only use LocalExecutor. What this issue is about, is the fact that sometime (randomly, and without any clear reason) one of the tasks (here also, it is random) gets stuck in ""queued"" state and never starts running. The manual workaround is to restart the task manually by clearing it. Does anyone have ideas about the issue behind, and how to avoid it for the future? Thanks in advance for your help. PS: other people are facing the same behaviour: [link|https://stackoverflow.com/questions/45853013/airflow-tasks-get-stuck-at-queued-status-and-never-gets-running]"
49,AIRFLOW-1693,AIRFLOW,1507533365000,1558123699000,Bug,Resolved,Blocker,1,1744,"airflow initdb throws errors I am having installation problems. The log for `airflow initdb` are Traceback (most recent call last): File ""/Users/gauripradeep/ENVS/scheduler/bin/airflow"", line 17, in <module> from airflow import configuration File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/airflow/__init__.py"", line 30, in <module> from airflow import settings File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/airflow/settings.py"", line 159, in <module> configure_orm() File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/airflow/settings.py"", line 147, in configure_orm engine = create_engine(SQL_ALCHEMY_CONN, **engine_args) File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/sqlalchemy/engine/__init__.py"", line 391, in create_engine return strategy.create(*args, **kwargs) File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py"", line 80, in create dbapi = dialect_cls.dbapi(**dbapi_args) File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/sqlalchemy/dialects/mysql/mysqldb.py"", line 110, in dbapi return __import__('MySQLdb') File ""/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/MySQLdb/__init__.py"", line 19, in <module> import _mysql ImportError: dlopen(/Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/_mysql.cpython-36m-darwin.so, 2): Library not loaded: /usr/local/opt/mysql/lib/libmysqlclient.20.dylib Referenced from: /Users/gauripradeep/ENVS/scheduler/lib/python3.6/site-packages/_mysql.cpython-36m-darwin.so Reason: image not found Other commands and dependencies pip3 install mysqlclient and pip3 install mysql-connector-python-rf pip3 install airflow[mysql]"
50,AIRFLOW-1711,AIRFLOW,1507839702000,1509388549000,Bug,Resolved,Blocker,1,460,"Ldap Attributes not always a ""list"" part 2 in the LDAP auth module `group_contains_user` checks for `resp['attributes'].get(user_name_attr)[0] == username` Some Ldaps apparently have this as a simple string `resp['attributes'].get(user_name_attr) == username` also should be checked. But really a test should be done to see if the return is a 'list' and perform the check differently. If its not a list, python will check both arguments and exit with an error."
51,AIRFLOW-1731,AIRFLOW,1508334610000,1509113011000,Bug,Resolved,Blocker,1,222,Import custom config on PYTHONPATH Currently the PYTHONPATH does not contain the required path to import a custom config as described. This needs to be fixed and the instructions needs to be updated based on user feedback.
52,AIRFLOW-1744,AIRFLOW,1508524368000,1508870800000,Bug,Resolved,Blocker,1,257,"task.retries can be False When adding the max_tries field task.retries can be False (e.g. in case of a faulty day). At least Postgres will not accept ""False"" for an integer field. It is proposed to set it to try_number in case try_number > 0 otherwise to 1."
53,AIRFLOW-1767,AIRFLOW,1509471930000,1509474151000,Bug,Resolved,Blocker,1,285,Airflow Scheduler no longer schedules DAGs The Airflow Scheduler no longer schedules DAGs after this commit on master: https://github.com/apache/incubator-airflow/commit/73549763eac74142b7c4018422bb2f8c897b45a8 Workers never receive any tasks and the scheduler never adjusts DAG state.
54,AIRFLOW-1891,AIRFLOW,1512640209000,1555601916000,Bug,Resolved,Blocker,1,455,Non-ascii character in default configuration template PR for AIRFLOW-966 introduced a non-ascii character (http://unicode.org/cldr/utility/character.jsp?a=2019) in default_airflow.cfg file that blocks Airflow from running when there is no prior configuration (or the configuration is generated from environment variables for example). More details here: https://github.com/apache/incubator-airflow/commit/aa737a582c687e7105ef934ffc4da3dc78438235#r26094657
55,AIRFLOW-1912,AIRFLOW,1513078723000,1535980389000,Bug,Resolved,Blocker,1,291,The log facility airflow.processor should not propagate The root logger will write to stdout. If redirection is used which is the case for processors and task runs (not runners) this can end up in an endless loop in case propagation is True. airflow.processor should not propagate therefore.
56,AIRFLOW-2007,AIRFLOW,1516088029000,1517666939000,Bug,Closed,Blocker,1,1080,"task failed first and then become green When I start to run a dag which contain only one task, the task failed immediately and then become green later. The task just call linux shell command to copy a big file from a folder to another. When I start the task, it become red(failed)(meanwhile, the dagrun become red too), but the ""copy"" process is running on the shell background normally. Then because the dagrun failed, the dag starts the next dag run and failed again. After the process finished normally, the task become green but the dagrun don't. Check: 1.I have checked the logs but there is no error log found. 2.After check the airflow database, I found task_instance table is inserted a failed task record when the task starts. dag_run table is inserted a running record. After a while the dag_run become failed. 3.For the job table, it is inserted a running record, and become success after the shell command finished.(which is normally process) My question: 1.Why the task failed immediately when it started. 2.Where does the airflow code modify the task_instance table?"
57,AIRFLOW-2008,AIRFLOW,1516125932000,1516280244000,Bug,Resolved,Blocker,1,96,Column default of timezone.utcnow() should be a callable Otherwise it will be all the same value
58,AIRFLOW-2058,AIRFLOW,1517538607000,1620203452000,Bug,Closed,Blocker,1,2540,"Scheduler uses MainThread for DAG file processing By reading the [source code |https://github.com/apache/incubator-airflow/blob/61ff29e578d1121ab4606fe122fb4e2db8f075b9/airflow/utils/dag_processing.py#L538] it appears the scheduler will process each DAG file, either a .py or .zip, using a new process. If I understand correctly, in theory what should happen in terms of processing a .zip file is that the dedicated process will add the .zip file to the PYTHONPATH, and load the file's module and dependency. When the DAG read is done, the process gets destroyed. And since the PYTHONPATH is process scoped, it won't pollute other processes. However by printing out the threads and process id, it looks like Airflow scheduler can sometimes accidentally pick up the main process instead of creating a new one, and that's when collision happens. Here is snippet of the PYTHONPATH when advanced_dag_dependency-1.zip is being processed. As you can see when it's executed by MainThread, it contains other .zip files. When it's using dedicated thread, only required .zip is added. sys.path :['/root/airflow/dags/yang_subdag_2.zip', '/root/airflow/dags/yang_subdag_2.zip', '/root/airflow/dags/yang_subdag_1.zip', '/root/airflow/dags/yang_subdag_1.zip', '/root/airflow/dags/advanced_dag_dependency-2.zip', '/root/airflow/dags/advanced_dag_dependency-2.zip', '/root/airflow/dags/advanced_dag_dependency-1.zip', '/root/airflow/dags/advanced_dag_dependency-1.zip', '/root/airflow/dags/yang_subdag_1', '/usr/local/bin', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/root/airflow/config', '/root/airflow/dags', '/root/airflow/plugins'] Print from MyFirstOperator in Dag 1 process id: 5059 thread id: <_MainThread(*MainThread*, started 140339858560768)> sys.path :[u'/root/airflow/dags/advanced_dag_dependency-1.zip', '/usr/local/bin', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/root/airflow/config', '/root/airflow/dags', '/root/airflow/plugins'] Print from MyFirstOperator in Dag 1 process id: 5076 thread id: <_MainThread(*DagFileProcessor283*, started 140137838294784)>"
59,AIRFLOW-2287,AIRFLOW,1523004855000,1523690070000,Improvement,Resolved,Blocker,1,978,"Missing and incorrect license headers * {color:#454545}a few files are missing licenses, like docs/Makefile{color} * {color:#454545}please fix year in notice (""2016 and onwards makes it a little bard to work out when copyright would expire){color} * {color:#454545}LICENSE is OK but some license texts are missing i.e. Bootstrap Toggle, normalize.css, parallel.js. Note that in order to comply with the terms of the the licenses the full text of the license MUST be included.{color} * {color:#454545}also note that ace and d3 are under a BSD 3 clause not BSD 2 clause{color} * {color:#454545} A large number of files are missing the correct ASF header. (see below){color} ** {color:#454545}Re incorrect header not perfect but shows scope of the issue:{color} *** {color:#454545} find . -name ""*.*"" -exec grep ""contributor license"" {} \; -print | wc{color} *** {color:#454545} find . -name ""*.*"" -exec grep ""[http://www.apache.org/licenses/LICENSE-2.0]"" {} \; -print | wc{color}"
60,AIRFLOW-2288,AIRFLOW,1523004955000,1540313991000,Improvement,Resolved,Blocker,1,131,Source tarball should not extract to root {color:#454545}the src tarball extracting to the current{color} directory was surprising.
61,AIRFLOW-2289,AIRFLOW,1523005004000,1585344026000,Improvement,Closed,Blocker,1,37,Add additional quick start to INSTALL
62,AIRFLOW-2290,AIRFLOW,1523005155000,1562254457000,Improvement,Open,Blocker,1,35,Include CVE references in changelog
63,AIRFLOW-2320,AIRFLOW,1523636561000,1535980215000,Bug,Open,Blocker,1,932,"Can not run DAGs since upgraded from Airflow 1.7 We installed Airflow 1.7, and used it for several months. I used PIP to uninstall ariflow 1.7 and install 1.9 (gory details are [here|[https://stackoverflow.com/questions/49544320/airflow-initdb-failed-importerror-no-module-named-log-logging-mixin]).] Since then, I haven't had a single DAG run. I renamed and moved log files to match the 1.9 expectations, but still nothing happens. I have a ""run every 40 minutes"" DAG, it hasn't run since 3/28. When I manually trigger it, no log file is created, nothing happens except I get a running DAG listed under ""DAG Runs"" (I do NOT get anything listed under ""Recent Tasks"", and ""Last Run"" does not get updated. I have a ""Run once"" DAG that I created. I triggered it, same behavior. I have also tried running the example_bash_operator DAG. Same behavior. (I've attached the example_bash_operator.py file, so we're clear what I tried to run)"
64,AIRFLOW-2355,AIRFLOW,1524299192000,1535911214000,Bug,Resolved,Blocker,1,383,"Airflow trigger tag parameters in subdag The command airflow {color:#8eb021}+_trigger_dag -c ""\{'name':'value'}""_+{color} sends conf parameters only to the parent DAG. I'm using SubDags that are dependent on these parameters. And no parameters are recieved by the SubDag. From source code of SubDag operator I see that there is no way of passing these trigger parameters to a Subdag."
65,AIRFLOW-2374,AIRFLOW,1524661485000,1535911731000,Bug,Resolved,Blocker,1,3966,"Airflow fails to show logs When viewing a log in the webserver, the page shows a loading gif and the log never appears. Looking in the Javascript console, the problem appears to be error 500 when loading the {{get_logs_with_metadata}} endpoint, givving the following trace: {code:java} ____/ ( ( ) ) \___ /( ( ( ) _ )) ) )\ (( ( )( ) ) ( ) ) ((/ ( _( ) ( _) ) ( () ) ) ( ( ( (_) (( ( ) .((_ ) . )_ ( ( ) ( ( ) ) ) . ) ( ) ( ( ( ( ) ( _ ( _) ). ) . ) ) ( ) ( ( ( ) ( ) ( )) ) _)( ) ) ) ( ( ( \ ) ( (_ ( ) ( ) ) ) ) )) ( ) ( ( ( ( (_ ( ) ( _ ) ) ( ) ) ) ( ( ( ( ( ) (_ ) ) ) _) ) _( ( ) (( ( )( ( _ ) _) _(_ ( (_ ) (_((__(_(__(( ( ( | ) ) ) )_))__))_)___) ((__) \\||lll|l||/// \_)) ( /(/ ( ) ) )\ ) ( ( ( ( | | ) ) )\ ) ( /(| / ( )) ) ) )) ) ( ( ((((_(|)_))))) ) ( ||\(|(|)|/|| ) ( |(||(||)|||| ) ( //|/l|||)|\\ \ ) (/ / // /|//||||\\ \ \ \ _) ------------------------------------------------------------------------------- Node: airflow-nods-dev ------------------------------------------------------------------------------- Traceback (most recent call last): File ""/opt/airflow/src/apache-airflow/airflow/utils/log/gcs_task_handler.py"", line 113, in _read remote_log = self.gcs_read(remote_loc) File ""/opt/airflow/src/apache-airflow/airflow/utils/log/gcs_task_handler.py"", line 131, in gcs_read return self.hook.download(bkt, blob).decode() File ""/opt/airflow/src/apache-airflow/airflow/contrib/hooks/gcs_hook.py"", line 107, in download .get_media(bucket=bucket, object=object) \ File ""/usr/local/lib/python3.6/dist-packages/oauth2client/_helpers.py"", line 133, in positional_wrapper return wrapped(*args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/googleapiclient/http.py"", line 841, in execute raise HttpError(resp, content, uri=self.uri) googleapiclient.errors.HttpError: <HttpError 404 when requesting https://www.googleapis.com/storage/v1/b/bucket-af/o/test-logs%2Fgeneric_transfer_single%2Ftransfer_file%2F2018-04-25T13%3A00%3A51.250983%2B00%3A00%2F1.log?alt=media returned ""Not Found""> During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/usr/local/lib/python3.6/dist-packages/flask/app.py"", line 1982, in wsgi_app response = self.full_dispatch_request() File ""/usr/local/lib/python3.6/dist-packages/flask/app.py"", line 1614, in full_dispatch_request rv = self.handle_user_exception(e) File ""/usr/local/lib/python3.6/dist-packages/flask/app.py"", line 1517, in handle_user_exception reraise(exc_type, exc_value, tb) File ""/usr/local/lib/python3.6/dist-packages/flask/_compat.py"", line 33, in reraise raise value File ""/usr/local/lib/python3.6/dist-packages/flask/app.py"", line 1612, in full_dispatch_request rv = self.dispatch_request() File ""/usr/local/lib/python3.6/dist-packages/flask/app.py"", line 1598, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File ""/usr/local/lib/python3.6/dist-packages/flask_admin/base.py"", line 69, in inner return self._run_view(f, *args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/flask_admin/base.py"", line 368, in _run_view return fn(self, *args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/flask_login.py"", line 758, in decorated_view return func(*args, **kwargs) File ""/opt/airflow/src/apache-airflow/airflow/www/utils.py"", line 269, in wrapper return f(*args, **kwargs) File ""/opt/airflow/src/apache-airflow/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/opt/airflow/src/apache-airflow/airflow/www/views.py"", line 770, in get_logs_with_metadata logs, metadatas = handler.read(ti, try_number, metadata=metadata) File ""/opt/airflow/src/apache-airflow/airflow/utils/log/file_task_handler.py"", line 164, in read log, metadata = self._read(task_instance, try_number, metadata) File ""/opt/airflow/src/apache-airflow/airflow/utils/log/gcs_task_handler.py"", line 120, in _read log += super(GCSTaskHandler, self)._read(ti, try_number) TypeError: must be str, not tuple{code}"
66,AIRFLOW-2387,AIRFLOW,1524850925000,1524858483000,Bug,Closed,Blocker,1,265,Flask 0.12.3 broke web component Recent release of flask 0.12.3 broke the webinterface with this message. Since requirement is >0.12 and < 0.13 any recent build will be broke {code:java} AttributeError: 'Blueprint' object has no attribute 'json_encoder' flask{code}
67,AIRFLOW-2453,AIRFLOW,1526027178000,1535911582000,Bug,Resolved,Blocker,1,1878,"Airflow init fail due lack of default settings kubernetes executor Since last changes in kubernetes config management for kubernetes executor, startup of airflow raise an exception if you dont have setted kubernetes/git_subpath which is was working previous this commit: [https://github.com/apache/incubator-airflow/commit/16bae5634df24132b37eb752fe816f51bf7e83ca#diff-b1d8d65aeaa7d031dfe5b197d6c5aa69L131] This is the trace: [2018-05-11 08:21:57,164] \{configuration.py:212} WARNING - section/key [kubernetes/git_subpath] not found in config Traceback (most recent call last): File ""/usr/local/bin/airflow"", line 22, in <module> from airflow.bin.cli import CLIFactory File ""/usr/local/lib/python2.7/dist-packages/airflow/bin/cli.py"", line 57, in <module> from airflow import jobs, settings File ""/usr/local/lib/python2.7/dist-packages/airflow/jobs.py"", line 71, in <module> class BaseJob(Base, LoggingMixin): File ""/usr/local/lib/python2.7/dist-packages/airflow/jobs.py"", line 103, in BaseJob executor=executors.GetDefaultExecutor(), File ""/usr/local/lib/python2.7/dist-packages/airflow/executors/__init__.py"", line 45, in GetDefaultExecutor DEFAULT_EXECUTOR = _get_executor(executor_name) File ""/usr/local/lib/python2.7/dist-packages/airflow/executors/__init__.py"", line 83, in _get_executor return KubernetesExecutor() File ""/usr/local/lib/python2.7/dist-packages/airflow/contrib/executors/kubernetes_executor.py"", line 440, in __init__ self.kube_config = KubeConfig() File ""/usr/local/lib/python2.7/dist-packages/airflow/contrib/executors/kubernetes_executor.py"", line 117, in __init__ self.git_subpath = conf.get(self.kubernetes_section, 'git_subpath') File ""/usr/local/lib/python2.7/dist-packages/airflow/configuration.py"", line 217, in get ""in config"".format(**locals())) airflow.exceptions.AirflowConfigException: section/key [kubernetes/git_subpath] not found in config"
68,AIRFLOW-2462,AIRFLOW,1526283251000,1535911320000,Bug,Resolved,Blocker,1,303,"airflow.contrib.auth.backends.password_auth.PasswordUser exists bug PasswordUser {quote} @password.setter def _set_password(self, plaintext): self._password = generate_password_hash(plaintext, 12) if PY3: self._password = str(self._password, 'utf-8') {quote} _set_password should be renamed as password."
69,AIRFLOW-2466,AIRFLOW,1526337663000,1535911347000,Bug,Resolved,Blocker,1,457,"_change_state_for_tis_without_dagrun ignores task_id on non-sqlite dbs This filter is supposed to choose tasks based on the subquery: [https://github.com/apache/incubator-airflow/blob/master/airflow/jobs.py#L1013] The filter, however, does not specify task_id, so it will indiscriminately change all tasks on a DagRun if anything matches. This can result in tasks succeeding and then being remarked as failed when a DagRun fails because of a different task."
70,AIRFLOW-2533,AIRFLOW,1527591716000,1535911323000,Bug,Resolved,Blocker,1,397,"Kubernetes worker configuration improperly sets path to DAG on worker node When triggering a DAG using the kubernetes executor, the path to the DAG on the worker node is not properly set due to the modification of the command that is sent to the pod for the worker node to perform. See !Screen Shot 2018-05-24 at 5.06.25 PM.png! This means that the only DAG's that are working at the example DAGs."
71,AIRFLOW-2573,AIRFLOW,1528320260000,1547920258000,Bug,Resolved,Blocker,1,560,"Cast TIMESTAMP field to float rather than int In current bigquery_hook.py, we have a `_bq_cast(string_field, bq_type)` function that help casts a BigQuery row to the appropriate data types. {quote}elif bq_type == 'INTEGER' or bq_type == 'TIMESTAMP': return int(string_field) {quote} However, when a bq_type equals to 'TIMESTAMP', it causes ValueError. {quote}>>> int('1.458668898E9') ValueError: invalid literal for int() with base 10: '1.458668898E9' {quote} Because 'TIMESTAMP' in bigquery is stored as double in python, thus should be cast to float instead."
72,AIRFLOW-2624,AIRFLOW,1529025673000,1535911173000,Bug,Closed,Blocker,1,416,"Airflow webserver broken out of the box `airflow webserver` and then click on any DAG, I get ``` File ""/Users/kevin_yang/ext_repos/incubator-airflow/airflow/www/utils.py"", line 364, in view_func return f(*args, **kwargs) File ""/Users/kevin_yang/ext_repos/incubator-airflow/airflow/www/utils.py"", line 251, in wrapper user = current_user.user.username AttributeError: 'NoneType' object has no attribute 'username' ```"
73,AIRFLOW-2697,AIRFLOW,1530279448000,1579455908000,Improvement,Open,Blocker,1,590,"Drop snakebite in favour of pyarrow The current HdfsHook relies on the snakebite library, which is unfortunately not compatible with Python 3. To add Python 3 support for the HdfsHook requires switching to a different library for interacting with HDFS. The hdfs3 library is an attractive alternative, as it supports Python 3 and seems to be stable and relatively well supported. Update: hdfs3 doesn't get any updates anymore. The best library right now seems to be pyarrow: https://arrow.apache.org/docs/python/filesystems.html Therefore I would like to upgrade to pyarrow instead of hdfs3."
74,AIRFLOW-2834,AIRFLOW,1533104423000,1554986424000,Bug,Resolved,Blocker,1,262,can not see the dag page after build from the newest code in github after build and deploy the newest version of code from github. got the web server opened and the dags page blank with the following error in request resource. !image-2018-08-01-14-20-09-256.png!
75,AIRFLOW-2859,AIRFLOW,1533536201000,1535027289000,Bug,Resolved,Blocker,1,186,DateTimes returned from the database are not converted to UTC This is due to the fact that sqlalchemy-utcdatetime does not convert to UTC when the database returns datetimes with tzinfo.
76,AIRFLOW-2870,AIRFLOW,1533681611000,1534076792000,Bug,Closed,Blocker,1,1493,"Migrations fail when upgrading from below cc1e65623dc7_add_max_tries_column_to_task_instance Running migrations from below cc1e65623dc7_add_max_tries_column_to_task_instance.py fail with: {noformat} INFO [alembic.runtime.migration] Context impl PostgresqlImpl. INFO [alembic.runtime.migration] Will assume transactional DDL. INFO [alembic.runtime.migration] Running upgrade 127d2bf2dfa7 -> cc1e65623dc7, add max tries column to task instance Traceback (most recent call last): File ""/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py"", line 1182, in _execute_context context) File ""/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py"", line 470, in do_execute cursor.execute(statement, parameters) psycopg2.ProgrammingError: column task_instance.executor_config does not exist LINE 1: ...ued_dttm, task_instance.pid AS task_instance_pid, task_insta... {noformat} The failure is occurring because cc1e65623dc7_add_max_tries_column_to_task_instance.py imports TaskInstance from the current code version, which has changes to the task_instance table that are not expected by the migration. Specifically, 27c6a30d7c24_add_executor_config_to_task_instance.py adds an executor_config column that does not exist as of when cc1e65623dc7_add_max_tries_column_to_task_instance.py is run. It is worth noting that this will not be observed for new installs because the migration branches on table existence/non-existence at a point that will hide the issue from new installs."
77,AIRFLOW-2881,AIRFLOW,1533835113000,1555353758000,Task,Resolved,Blocker,1,385,Add compile_assets to Release Process Documentation AIRFLOW-2691 introduced a `compile_assets` command in setup.py that is required during a release. This should be added to the [release notes|https://cwiki.apache.org/confluence/display/AIRFLOW/Releasing+Airflow#ReleasingAirflow-PublishingtoPyPi] after 1.10.x has been released. {code:java} python setup.py compile_assets sdist {code}
78,AIRFLOW-2898,AIRFLOW,1534254553000,1559208556000,Bug,Closed,Blocker,1,595,"Task not entering queued state for pool I have a pool of 3 and have several jobs (over 10) which use the pool. Tasks timeout (after 10 mins) from being stuck in scheduled state when the tasks should be in queued state for the pool. to reproduce: use attached dag, and create a pool called ""backfill"" with 2 slots start the dag, and go to this url - > <your_server_addr_here>/admin/taskinstance/?flt0_pool_equals=backfill you'll see two light green ""running"" state, loads of white ""scheduled"" state and none in grey ""queued"" state. what I expect would be two in running, the rest in queued state."
79,AIRFLOW-2934,AIRFLOW,1534932541000,1558132710000,Bug,Resolved,Blocker,1,373,"Pools not respected for internal subdag tasks I'm trying to have some subdags execute one task at a time. The way I found was to create a first pool for the SubdagOperators (pool1 in the attached code file) and a second one for the internal tasks (pool2). However, it appears that pools for subdag elements are not being respected. Running airflow 1.9.0 with LocalExecutor."
80,AIRFLOW-2952,AIRFLOW,1535063109000,1547067304000,Bug,Resolved,Blocker,1,481,Dockerized CI pipeline has silently broken integration testing for KubernetesExecutor [~gcuriel] [~bolke] [~Fokko] Looking at all recent builds the new CI pipeline is silently reverting the kubernetes tests to the normal airflow tests. Before https://travis-ci.org/apache/incubator-airflow/jobs/418914949#L1007 After: [https://travis-ci.org/apache/incubator-airflow/jobs/419062412#L4970] This means that kubernetes builds will pass without actually testing on a kubernetes cluster.
81,AIRFLOW-3032,AIRFLOW,1536570441000,1572965437000,Bug,Resolved,Blocker,1,726,"_pickle.UnpicklingError with using remote MySQL Server Hello, I am running Airflow 1.9.0 successfully with a localhost MySQL database, version 5.7.23. I switched sql_alchemy_conn = mysql://airflow:<password>@<remote-host>:3306/airflow in order to use the proper MySQL server - same version 5.7.23. I created a dump from my local instance to the remote one. Issue: * When tasks are executed by the scheduler everything runs fine, tasks are executed and DB updated * When manually triggering a task via the webserver, I am getting ""_pickle.UnpicklingError"" please see error__log.txt for full log In the end, I only changed this one line in airflow.cfg which is causing that I can not use it with a remote MySQL server. Best, Max"
82,AIRFLOW-3036,AIRFLOW,1536627406000,1612366338000,Bug,Reopened,Blocker,1,3213,"Upgrading to Airflow 1.10 not possible using GCP Cloud SQL for MYSQL The upgrade path to airflow 1.10 seems impossible for users of MySQL in Google's Cloud SQL service given new mysql requirements for 1.10. When executing ""airflow upgradedb"" ``` INFO [alembic.runtime.migration] Running upgrade d2ae31099d61 -> 0e2a74e0fc9f, Add time zone awareness Traceback (most recent call last): File ""/usr/local/bin/airflow"", line 32, in <module> args.func(args) File ""/usr/local/lib/python3.6/site-packages/airflow/bin/cli.py"", line 1002, in initdb db_utils.initdb(settings.RBAC) File ""/usr/local/lib/python3.6/site-packages/airflow/utils/db.py"", line 92, in initdb upgradedb() File ""/usr/local/lib/python3.6/site-packages/airflow/utils/db.py"", line 346, in upgradedb command.upgrade(config, 'heads') File ""/usr/local/lib/python3.6/site-packages/alembic/command.py"", line 174, in upgrade script.run_env() File ""/usr/local/lib/python3.6/site-packages/alembic/script/base.py"", line 416, in run_env util.load_python_file(self.dir, 'env.py') File ""/usr/local/lib/python3.6/site-packages/alembic/util/pyfiles.py"", line 93, in load_python_file module = load_module_py(module_id, path) File ""/usr/local/lib/python3.6/site-packages/alembic/util/compat.py"", line 68, in load_module_py module_id, path).load_module(module_id) File ""<frozen importlib._bootstrap_external>"", line 399, in _check_name_wrapper File ""<frozen importlib._bootstrap_external>"", line 823, in load_module File ""<frozen importlib._bootstrap_external>"", line 682, in load_module File ""<frozen importlib._bootstrap>"", line 265, in _load_module_shim File ""<frozen importlib._bootstrap>"", line 684, in _load File ""<frozen importlib._bootstrap>"", line 665, in _load_unlocked File ""<frozen importlib._bootstrap_external>"", line 678, in exec_module File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed File ""/usr/local/lib/python3.6/site-packages/airflow/migrations/env.py"", line 91, in <module> run_migrations_online() File ""/usr/local/lib/python3.6/site-packages/airflow/migrations/env.py"", line 86, in run_migrations_online context.run_migrations() File ""<string>"", line 8, in run_migrations File ""/usr/local/lib/python3.6/site-packages/alembic/runtime/environment.py"", line 807, in run_migrations self.get_context().run_migrations(**kw) File ""/usr/local/lib/python3.6/site-packages/alembic/runtime/migration.py"", line 321, in run_migrations step.migration_fn(**kw) File ""/usr/local/lib/python3.6/site-packages/airflow/migrations/versions/0e2a74e0fc9f_add_time_zone_awareness.py"", line 46, in upgrade raise Exception(""Global variable explicit_defaults_for_timestamp needs to be on (1) for mysql"") Exception: Global variable explicit_defaults_for_timestamp needs to be on (1) for mysql ``` Reading documentation for upgrading to airflow 1.10, it seems the requirement for explicit_defaults_for_timestamp=1 was intentional. However, MySQL on Google Cloud SQL does not support configuring this variable and it is off by default. Users of MySQL and Cloud SQL do not have an upgrade path to 1.10. Alas, so close to the mythical Kubernetes Executor. In GCP, Cloud SQL is _the_ hosted MySQL solution. [https://cloud.google.com/sql/docs/mysql/flags]"
83,AIRFLOW-3118,AIRFLOW,1537955437000,1543246477000,Bug,Resolved,Blocker,1,1245,"DAGs not successful on new installation When trying out Airflow, on localhost, none of the DAG runs are getting to the 'success' state. They are getting stuck in 'running', or I manually label them as failed: !image-2018-09-26-12-39-03-094.png! h2. Steps to reproduce # create new conda environment ** conda create -n airflow ** source activate airflow # install airflow ** pip install apache-airflow # initialize Airflow db ** airflow initdb # disable default paused setting in airflow.cfg ** dags_are_paused_at_creation = False # {color:#6a8759}run airflow and airflow scheduler (in separate terminal){color} ** {color:#6a8759}airflow scheduler{color} ** {color:#6a8759}airflow webserver{color} # {color:#6a8759}unpause example_bash_operator{color} ** {color:#6a8759}airflow unpause example_bash_operator{color} # {color:#6a8759}log in to Airflow UI{color} # {color:#6a8759}turn on example_bash_operator{color} # {color:#6a8759}click ""Trigger DAG"" in `example_bash_operator` row{color} h2. {color:#6a8759}Observed result{color} {color:#6a8759}The `example_bash_operator` never leaves the ""running"" state.{color} h2. {color:#6a8759}Expected result{color} {color:#6a8759}The `example_bash_operator` would quickly enter the ""success"" state{color}"
84,AIRFLOW-3164,AIRFLOW,1538760099000,1543351951000,Bug,Resolved,Blocker,1,130,verify certificate of LDAP server Currently we dont verify the certificate of the Ldap server this can lead to security incidents.
85,AIRFLOW-3180,AIRFLOW,1539139409000,1539157943000,Bug,Closed,Blocker,1,4751,"Chinese characters all become gibberish when using BashOperator beeline command insert data into hive table with BashOperator ,i use beeline to insert data into hive ,hql with chinese characters ,after dag run success,hive data contain unreadable code. python : {code:java} # -*- coding: utf-8 -*- import airflow from airflow.models import DAG from airflow.operators.bash_operator import BashOperator from airflow.operators.python_operator import BranchPythonOperator from datetime import datetime import time from datetime import timedelta import sys import pendulum local_tz = pendulum.timezone(""Asia/Shanghai"") reload(sys) sys.setdefaultencoding('utf-8') default_args = { 'owner': 'airflow', 'depends_on_past':False, 'start_date':datetime(2018,10,9,19,22,20,tzinfo=local_tz), 'retries':0 } dag = DAG( 'inserthiveutf8', default_args=default_args, description='null', catchup=False, schedule_interval=None ) adf37 = r"""""" beeline -u ""jdbc:hive2://10.138.***.***:30010/di_zz"" -n ""*****"" -p ""*****"" -e ""insert into di_zz.tt_wms_inout_detail_new(fac_id) values ('')"" """""" abcd8491539084126613 =BashOperator( task_id='abcd8491539084126613', bash_command=adf37, dag=dag){code} i have tried this: {code:java} abcd8491539084126613 =BashOperator( task_id='abcd8491539084126613', bash_command=""sh ~/insert.sh "", dag=dag){code} this: {code:java} export LANG=en_US.UTF-8 beeline -u ""jdbc:hive2://10.138.***.***:30010/di_zz"" -n ""*****"" -p ""*****"" -e 'insert into di_zz.tt_wms_inout_detail_new(fac_id) values ("""")'{code} this: {code:java} beeline -u ""jdbc:hive2://10.138.***.***:30010/di_zz"" -n ""*****"" -p ""*****"" -f ~/hql.sql{code} log: {code:java} [2018-10-09 21:00:58,485] {bash_operator.py:110} INFO - INFO : Compiling command(queryId=hive_20181009210000_89390a92-c4de-413f-9958-4d7da1065ef9): insert into di_zz.tt_wms_inout_detail_new(fac_id) values (""???"") [2018-10-09 21:00:58,485] {bash_operator.py:110} INFO - INFO : Semantic Analysis Completed [2018-10-09 21:00:58,486] {bash_operator.py:110} INFO - INFO : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:_col0, type:timestamp, comment:null), FieldSchema(name:_col1, type:string, comment:null), FieldSchema(name:_col2, type:void, comment:null), FieldSchema(name:_col3, type:void, comment:null), FieldSchema(name:_col4, type:void, comment:null), FieldSchema(name:_col5, type:void, comment:null), FieldSchema(name:_col6, type:void, comment:null), FieldSchema(name:_col7, type:bigint, comment:null), FieldSchema(name:_col8, type:bigint, comment:null), FieldSchema(name:_col9, type:bigint, comment:null), FieldSchema(name:_col10, type:void, comment:null), FieldSchema(name:_col11, type:timestamp, comment:null)], properties:null) [2018-10-09 21:00:58,486] {bash_operator.py:110} INFO - INFO : Completed compiling command(queryId=hive_20181009210000_89390a92-c4de-413f-9958-4d7da1065ef9); Time taken: 0.291 seconds [2018-10-09 21:00:58,486] {bash_operator.py:110} INFO - INFO : Executing command(queryId=hive_20181009210000_89390a92-c4de-413f-9958-4d7da1065ef9): insert into di_zz.tt_wms_inout_detail_new(fac_id) values (""???"") [2018-10-09 21:00:58,486] {bash_operator.py:110} INFO - INFO : Query ID = hive_20181009210000_89390a92-c4de-413f-9958-4d7da1065ef9 {code} data: {code:java} +------------------------------------+---------------------------------+-----------------------------------+----------------------------------+------------------------------------+------------------------------------+---------------------------------------+-----------------------------------+----------------------------------+-----------------------------------+-------------------------------------------+--------------------------------------+--+ | tt_wms_inout_detail_new.stat_date | tt_wms_inout_detail_new.fac_id | tt_wms_inout_detail_new.fac_name | tt_wms_inout_detail_new.ware_id | tt_wms_inout_detail_new.ware_name | tt_wms_inout_detail_new.ware_type | tt_wms_inout_detail_new.product_code | tt_wms_inout_detail_new.ware_cnt | tt_wms_inout_detail_new.ware_in | tt_wms_inout_detail_new.ware_out | tt_wms_inout_detail_new.sap_factory_name | tt_wms_inout_detail_new.di_etl_date | +------------------------------------+---------------------------------+-----------------------------------+----------------------------------+------------------------------------+------------------------------------+---------------------------------------+-----------------------------------+----------------------------------+-----------------------------------+-------------------------------------------+--------------------------------------+--+ | NULL |  | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | {code} this is a simple example .the production script is comlex more Thanks in advance."
86,AIRFLOW-3224,AIRFLOW,1539779882000,1558149209000,Bug,Resolved,Blocker,1,807,"Flask Errors when Installing Airflow 1.10 in Kubernetes I am currently working on deploying Apache Airflow 1.10.0 to a Kubernetes cluster. I am running into some dependency issues with Flask. If I use the current version of flask-login (0.4.1), I receive this error: {{apache-airflow 1.10.0 has requirement flask-login==0.2.11, but you'll have flask-login 0.4.1 which is incompatible.}} With this error, the UI won't render, and instead, I see a text bomb followed by many flask-appbuilder/flask-login warnings. If I use the Airflow's requirement of flask-login (0.2.11), I receive this error: {{flask-appbuilder 1.12.0 has requirement Flask-Login<0.5,>=0.3, but you'll have flask-login 0.2.11 which is incompatible.}} With this error, the UI renders with Airflow 1.9 features and CeleryExecutor won't work."
87,AIRFLOW-3259,AIRFLOW,1540496248000,1547913373000,Bug,Resolved,Blocker,1,1116,"Internal Server Error when creating charts because of sort function h2. {color:#205081}*Problem*{color} h3. When you try to create a chart and display metrics you get an internal server error (See picture below). h3. !Screen Shot 2018-10-25 at 8.01.09 PM.png|width=605,height=222! h2. {color:#205081}*Cause*{color} h3. When you click on the url rendering the internal server error you get this: (See picture below) h2. !Screen Shot 2018-10-25 at 8.01.52 PM.png|width=605,height=535! h3. A dependency issue: the function ""sort"" was deprecated and is no longer a part of pandas Dataframe and thus it creates a problem when creating charts in airflow. h2. {color:#205081}*Solution*{color} h3. The sort function needs to replaced by sort_values instead (See code below) {code:java} # Replace this df = df.sort(df.columns[0]) # By this df = df.sort_values(by=df.columns[0]) {code} In views.py (See picture below) !Screen Shot 2018-10-25 at 8.02.50 PM.png|width=603,height=593! h2. {color:#205081}*Result*{color} The data is loaded and the chart displayed :D !Screen Shot 2018-10-25 at 8.16.53 PM.png|width=607,height=245!"
88,AIRFLOW-3270,AIRFLOW,1540832243000,1556107413000,Bug,Closed,Blocker,1,989,"Apache airflow 1.10.0 integration with LDAP anonmyously Please advise what to include in airflow.cfg when going to integrate with LDAP anonymously ? We are using DS389 as LDAP server vendor name. {noformat} [webserver] authenticate = True auth_backend = airflow.contrib.auth.backends.ldap_auth {noformat} And {noformat} [ldap] uri = ldap://nsp-daf178e8.ad1.prd.us-phx.odc.im:389 user_filter = memberOf=cn=rvs-all-prd_usphx,ou=groups,dc=odc,dc=im user_name_attr = uid group_member_attr = superuser_filter = memberOf=cn=rvd-sudo_all-prd_usphx,ou=groups,dc=odc,dc=im data_profiler_filter = bind_user = bind_password = basedn = ou=people,dc=odc,dc=im cacert = /opt/orchestration/airflow/ldap_ca.crt search_scope = LEVEL {noformat} I am hitting below exception: {noformat} File ""/usr/local/lib/python3.5/site-packages/ldap3/operation/search.py"", line 215, in parse_filter raise LDAPInvalidFilterError('malformed filter') ldap3.core.exceptions.LDAPInvalidFilterError: malformed filter {noformat}"
89,AIRFLOW-3277,AIRFLOW,1540929816000,1543520989000,Bug,Resolved,Blocker,1,415,"Invalid timezone transition handling for cron schedules `following_schedule` converts to naive time by using the local time zone. In case of a DST transition, say 3AM -> 2AM (""summer time to winter time"") we generate date times that could overlap with earlier schedules. Therefore a DAG that should run every 5 minutes will not do so if it has already seen the schedule. We should not convert to naive and keep UTC."
90,AIRFLOW-3279,AIRFLOW,1540983715000,1555353752000,Bug,Closed,Blocker,1,4322,"Documentation for Google Logging unclear The documentation of how to install logging to a Google Cloud bucket is unclear. I am now following the tutorial on the airflow page: [https://airflow.apache.org/howto/write-logs.html] Here I find it unclear what part of the 'logger' I have to adjust in the `{{airflow/config_templates/airflow_local_settings.py}}`. The adjustment states: # Update the airflow.task and airflow.tas_runner blocks to be 'gcs.task' instead of 'file.task'. 'loggers': Unknown macro: \{ 'airflow.task'} However what I find in the template is: |'loggers': \{\| \|'airflow.processor': { \\\\\\\\| \\\\\\\\|'handlers': ['processor'], \\\\\\\\| \\\\\\\\|'level': LOG_LEVEL, \\\\\\\\| \\\\\\\\|'propagate': False, \\\\\\\\| \\\\\\\\|},| |'airflow.task': { \| \|'handlers': ['task'], \| \|'level': LOG_LEVEL, \| \|'propagate': False, \| \|},| |'flask_appbuilder': { \| \|'handler': ['console'], \| \|'level': FAB_LOG_LEVEL, \| \|'propagate': True, \| \|}| }, Since for me it is very important to do it right at the first time I hope some clarity can be provided in what has to be adjusted in the logger. Is it only the 'airflow.task' or more? Furthermore, at step 6 it is a little unclear what remote_log_conn_id means. I would propose to add a little more information to make this more clear. The current error I am facing is: Traceback (most recent call last): File ""/usr/local/bin/airflow"", line 16, in <module> from airflow import configuration File ""/usr/local/lib/python2.7/site-packages/airflow/__init__.py"", line 31, in <module> from airflow import settings File ""/usr/local/lib/python2.7/site-packages/airflow/settings.py"", line 198, in <module> configure_logging() File ""/usr/local/lib/python2.7/site-packages/airflow/logging_config.py"", line 71, in configure_logging dictConfig(logging_config) File ""/usr/local/lib/python2.7/logging/config.py"", line 794, in dictConfig dictConfigClass(config).configure() File ""/usr/local/lib/python2.7/logging/config.py"", line 568, in configure handler = self.configure_handler(handlers[name]) File ""/usr/local/lib/python2.7/logging/config.py"", line 733, in configure_handler result = factory(**kwargs) File ""/usr/local/lib/python2.7/site-packages/airflow/utils/log/gcs_task_handler.py"", line 30, in __init__ super(GCSTaskHandler, self).__init__(base_log_folder, filename_template) File ""/usr/local/lib/python2.7/site-packages/airflow/utils/log/file_task_handler.py"", line 46, in __init__ self.filename_jinja_template = Template(self.filename_template) File ""/usr/local/lib/python2.7/site-packages/jinja2/environment.py"", line 926, in __new__ return env.from_string(source, template_class=cls) File ""/usr/local/lib/python2.7/site-packages/jinja2/environment.py"", line 862, in from_string return cls.from_code(self, self.compile(source), globals, None) File ""/usr/local/lib/python2.7/site-packages/jinja2/environment.py"", line 565, in compile self.handle_exception(exc_info, source_hint=source_hint) File ""/usr/local/lib/python2.7/site-packages/jinja2/environment.py"", line 754, in handle_exception reraise(exc_type, exc_value, tb) File ""<unknown>"", line 1, in template jinja2.exceptions.TemplateSyntaxError: expected token ':', got '}' Error in atexit._run_exitfuncs: Traceback (most recent call last): File ""/usr/local/lib/python2.7/atexit.py"", line 24, in _run_exitfuncs func(*targs, **kargs) File ""/usr/local/lib/python2.7/logging/__init__.py"", line 1676, in shutdown h.close() File ""/usr/local/lib/python2.7/site-packages/airflow/utils/log/gcs_task_handler.py"", line 73, in close if self.closed: AttributeError: 'GCSTaskHandler' object has no attribute 'closed' Error in sys.exitfunc: Traceback (most recent call last): File ""/usr/local/lib/python2.7/atexit.py"", line 24, in _run_exitfuncs func(*targs, **kargs) File ""/usr/local/lib/python2.7/logging/__init__.py"", line 1676, in shutdown h.close() File ""/usr/local/lib/python2.7/site-packages/airflow/utils/log/gcs_task_handler.py"", line 73, in close if self.closed: AttributeError: 'GCSTaskHandler' object has no attribute 'closed' If I look at the Airflow code I see the following code for the GcsTaskHandler: https://github.com/apache/incubator-airflow/blob/v1-10-stable/airflow/utils/log/gcs_task_handler.py Here the closed attributed indeed refers to nowhere, does somebody know how to resolve this issue?"
91,AIRFLOW-3326,AIRFLOW,1541993099000,1551956209000,Bug,Closed,Blocker,1,2645,"High Sierra Complaining 'in progress in another thread when fork() was called' Inside the plugins folder, I have a hook that is a child class of BigQueryHook. {code:java} // code from airflow.contrib.hooks.bigquery_hook import BigQueryHook class BQHook(BigQueryHook): pass{code} When I run the airflow server, it keeps throwing messages complaining 'in progress in another thread when fork() was called', and I can't use the web server UI at all. {code:java} // messages from terminal objc[15098]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. objc[15098]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug. [2018-11-12 14:03:40 +1100] [15102] [INFO] Booting worker with pid: 15102 [2018-11-12 14:03:40,792] {__init__.py:51} INFO - Using executor SequentialExecutor [2018-11-12 14:03:40,851] {base_hook.py:83} INFO - Using connection to: https://custom-data-z00100-dev.appspot.com/ objc[15099]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. objc[15099]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug. [2018-11-12 14:03:40 +1100] [15103] [INFO] Booting worker with pid: 15103 [2018-11-12 14:03:40,902] {base_hook.py:83} INFO - Using connection to: https://custom-data-z00100-dev.appspot.com/ objc[15101]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. objc[15101]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug. [2018-11-12 14:03:40 +1100] [15104] [INFO] Booting worker with pid: 15104 [2018-11-12 14:03:40,948] {base_hook.py:83} INFO - Using connection to: https://custom-data-z00100-dev.appspot.com/ objc[15100]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. objc[15100]: +[__NSPlaceholderDate initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug. {code}"
92,AIRFLOW-3339,AIRFLOW,1542197133000,1542231430000,Bug,Resolved,Blocker,1,3497,"Timezone error when start_date in default_args From slack: nicor88 8:34 AM {quote} Hey all, we are having issue with our scheduler, in the latest release 1.10.1 due to this error: {noformat} Process DagFileProcessor94249-Process: Traceback (most recent call last): File ""/usr/local/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap self.run() File ""/usr/local/lib/python3.6/multiprocessing/process.py"", line 93, in run self._target(*self._args, **self._kwargs) File ""/usr/local/lib/python3.6/site-packages/airflow/jobs.py"", line 389, in helper pickle_dags) File ""/usr/local/lib/python3.6/site-packages/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/usr/local/lib/python3.6/site-packages/airflow/jobs.py"", line 1846, in process_file self._process_dags(dagbag, dags, ti_keys_to_schedule) File ""/usr/local/lib/python3.6/site-packages/airflow/jobs.py"", line 1426, in _process_dags dag_run = self.create_dag_run(dag) File ""/usr/local/lib/python3.6/site-packages/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/usr/local/lib/python3.6/site-packages/airflow/jobs.py"", line 835, in create_dag_run next_start = dag.following_schedule(now) File ""/usr/local/lib/python3.6/site-packages/airflow/models.py"", line 3396, in following_schedule tz = pendulum.timezone(self.timezone.name) AttributeError: 'NoneType' object has no attribute 'name' {noformat} We have a timezone setup in the config {quote} eamon [Today at 9:41 AM] {quote} @nicor88 I saw that in the logs also, fwiw it seemed to fail at the first dag run but then subsequent attempts seemed to work. {quote}  nicor88 [3 hours ago] {quote} I tried but the daily jobs are stacked {quote}  eamon [2 hours ago] {quote} so nothing getting scheduled? This is the behaviour I've observed also. When I saw that particular error, it seemed to correct itself so I discounted that as the root cause but could be it. {quote}  eamon [2 hours ago] {quote} maybe try a task without a timezone. {quote}  porn [1 hour ago] {quote} dammit, same problem here ({{1.10.1-rc1}}) {quote}  nicor88 [1 hour ago] {quote} we have timezone setup as utc in the config, and the start_date is setup like: datetime(2018, 7, 23) {quote}  nicor88 [1 hour ago] {quote} we reverted to the stable release 1.10.0 {quote}  porn [1 hour ago] {quote} {{default_timezone = utc}} in config too, the DAG parameters: {noformat} schedule_interval = ""0 14 * * *"", start_date = datetime(2017, 8, 29, hour=1) {noformat} {quote}  porn [1 hour ago] {quote} I need to add that this happened to me only when tried to manually execute (from UI) the task that is periodical, but haven't ran yet. Can you @nicor88 confirm this was your case too? {quote}  nicor88 [1 hour ago] {quote} in our case the daily jobs were not scheduled at all {quote}  nicor88 [1 hour ago] {quote} thats why I got suspiscious and check (edited) {quote}  nicor88 [1 hour ago] {quote} we install Airflow from Github directly, pointing to the stable branch. Now we recovered pointing to a specific release {quote}  porn [1 hour ago] {quote} it is a pre-release actually {quote} nicor88 [1 hour ago] {quote} its my bad that we use the v1-10-stable branch from Github {quote}  nicor88 [1 hour ago] {quote} instead of using the tagged release (edited) {quote}  nicor88 [1 hour ago] {quote} lesson learned {quote}  porn [14 minutes ago] {quote} ok, just downgraded to {{v1.10.1b1}} and got the same error {quote}"
93,AIRFLOW-3351,AIRFLOW,1542278910000,1549373211000,Bug,Open,Blocker,1,13039,"Airflow webserver intermitent broken After completing the airflow 1.10.0 integration with LDAP anonymously (AIRFLOW-3270), we started to hit ""Internal Server Error"" with below exception stack, we tried to clean up the browser cache, it sometimes works and sometimes error our. Please advise the resolution to avoid this issue. {code:java} During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/usr/local/lib/python3.5/site-packages/gunicorn/workers/sync.py"", line 135, in handle self.handle_request(listener, req, client, addr) File ""/usr/local/lib/python3.5/site-packages/gunicorn/workers/sync.py"", line 176, in handle_request respiter = self.wsgi(environ, resp.start_response) File ""/usr/local/lib/python3.5/site-packages/werkzeug/wsgi.py"", line 826, in __call__ return app(environ, start_response) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1997, in __call__ return self.wsgi_app(environ, start_response) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1985, in wsgi_app response = self.handle_exception(e) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1547, in handle_exception return self.finalize_request(handler(e), from_error_handler=True) File ""/usr/local/lib/python3.5/site-packages/airflow/www/views.py"", line 716, in show_traceback info=traceback.format_exc()), 500 File ""/usr/local/lib/python3.5/site-packages/flask/templating.py"", line 132, in render_template ctx.app.update_template_context(context) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 764, in update_template_context context.update(func()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 825, in _user_context_processor return dict(current_user=_get_user()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 794, in _get_user current_app.login_manager._load_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 363, in _load_user return self.reload_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 325, in reload_user user = self.user_callback(user_id) File ""/usr/local/lib/python3.5/site-packages/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 278, in load_user return LdapUser(user) File ""<string>"", line 4, in __init__ File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 414, in _initialize_instance manager.dispatch.init_failure(self, args, kwargs) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py"", line 66, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/compat.py"", line 187, in reraise raise value File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 411, in _initialize_instance return manager.original_init(*mixed[1:], **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 157, in __init__ user.username) AttributeError: 'NoneType' object has no attribute 'username' 127.0.0.1 - - [15/Nov/2018:10:47:31 +0000] ""GET /admin/ HTTP/1.1"" 500 0 ""-"" ""-"" [2018-11-15 10:47:38,590] ERROR in app: Exception on /favicon.ico [GET] Traceback (most recent call last): File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1612, in full_dispatch_request rv = self.dispatch_request() File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1590, in dispatch_request self.raise_routing_exception(req) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1573, in raise_routing_exception raise request.routing_exception File ""/usr/local/lib/python3.5/site-packages/flask/ctx.py"", line 294, in match_request self.url_adapter.match(return_rule=True) File ""/usr/local/lib/python3.5/site-packages/werkzeug/routing.py"", line 1581, in match raise NotFound() werkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again. During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1982, in wsgi_app response = self.full_dispatch_request() File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1614, in full_dispatch_request rv = self.handle_user_exception(e) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1512, in handle_user_exception return self.handle_http_exception(e) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1471, in handle_http_exception return handler(e) File ""/usr/local/lib/python3.5/site-packages/airflow/www/views.py"", line 707, in circles 'airflow/circles.html', hostname=get_hostname()), 404 File ""/usr/local/lib/python3.5/site-packages/flask/templating.py"", line 132, in render_template ctx.app.update_template_context(context) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 764, in update_template_context context.update(func()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 825, in _user_context_processor return dict(current_user=_get_user()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 794, in _get_user current_app.login_manager._load_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 363, in _load_user return self.reload_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 325, in reload_user user = self.user_callback(user_id) File ""/usr/local/lib/python3.5/site-packages/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 278, in load_user return LdapUser(user) File ""<string>"", line 4, in __init__ File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 414, in _initialize_instance manager.dispatch.init_failure(self, args, kwargs) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py"", line 66, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/compat.py"", line 187, in reraise raise value File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 411, in _initialize_instance return manager.original_init(*mixed[1:], **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 157, in __init__ user.username) AttributeError: 'NoneType' object has no attribute 'username' [2018-11-15 10:47:38 +0000] [78] [ERROR] Error handling request /favicon.ico Traceback (most recent call last): File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1612, in full_dispatch_request rv = self.dispatch_request() File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1590, in dispatch_request self.raise_routing_exception(req) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1573, in raise_routing_exception raise request.routing_exception File ""/usr/local/lib/python3.5/site-packages/flask/ctx.py"", line 294, in match_request self.url_adapter.match(return_rule=True) File ""/usr/local/lib/python3.5/site-packages/werkzeug/routing.py"", line 1581, in match raise NotFound() werkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again. During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1982, in wsgi_app response = self.full_dispatch_request() File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1614, in full_dispatch_request rv = self.handle_user_exception(e) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1512, in handle_user_exception return self.handle_http_exception(e) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1471, in handle_http_exception return handler(e) File ""/usr/local/lib/python3.5/site-packages/airflow/www/views.py"", line 707, in circles 'airflow/circles.html', hostname=get_hostname()), 404 File ""/usr/local/lib/python3.5/site-packages/flask/templating.py"", line 132, in render_template ctx.app.update_template_context(context) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 764, in update_template_context context.update(func()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 825, in _user_context_processor return dict(current_user=_get_user()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 794, in _get_user current_app.login_manager._load_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 363, in _load_user return self.reload_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 325, in reload_user user = self.user_callback(user_id) File ""/usr/local/lib/python3.5/site-packages/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 278, in load_user return LdapUser(user) File ""<string>"", line 4, in __init__ File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 414, in _initialize_instance manager.dispatch.init_failure(self, args, kwargs) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py"", line 66, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/compat.py"", line 187, in reraise raise value File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 411, in _initialize_instance return manager.original_init(*mixed[1:], **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 157, in __init__ user.username) AttributeError: 'NoneType' object has no attribute 'username' During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/usr/local/lib/python3.5/site-packages/gunicorn/workers/sync.py"", line 135, in handle self.handle_request(listener, req, client, addr) File ""/usr/local/lib/python3.5/site-packages/gunicorn/workers/sync.py"", line 176, in handle_request respiter = self.wsgi(environ, resp.start_response) File ""/usr/local/lib/python3.5/site-packages/werkzeug/wsgi.py"", line 826, in __call__ return app(environ, start_response) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1997, in __call__ return self.wsgi_app(environ, start_response) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1985, in wsgi_app response = self.handle_exception(e) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 1547, in handle_exception return self.finalize_request(handler(e), from_error_handler=True) File ""/usr/local/lib/python3.5/site-packages/airflow/www/views.py"", line 716, in show_traceback info=traceback.format_exc()), 500 File ""/usr/local/lib/python3.5/site-packages/flask/templating.py"", line 132, in render_template ctx.app.update_template_context(context) File ""/usr/local/lib/python3.5/site-packages/flask/app.py"", line 764, in update_template_context context.update(func()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 825, in _user_context_processor return dict(current_user=_get_user()) File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 794, in _get_user current_app.login_manager._load_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 363, in _load_user return self.reload_user() File ""/usr/local/lib/python3.5/site-packages/flask_login.py"", line 325, in reload_user user = self.user_callback(user_id) File ""/usr/local/lib/python3.5/site-packages/airflow/utils/db.py"", line 74, in wrapper return func(*args, **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 278, in load_user return LdapUser(user) File ""<string>"", line 4, in __init__ File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 414, in _initialize_instance manager.dispatch.init_failure(self, args, kwargs) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py"", line 66, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/util/compat.py"", line 187, in reraise raise value File ""/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/state.py"", line 411, in _initialize_instance return manager.original_init(*mixed[1:], **kwargs) File ""/usr/local/lib/python3.5/site-packages/airflow/contrib/auth/backends/ldap_auth.py"", line 157, in __init__ user.username) AttributeError: 'NoneType' object has no attribute 'username' 127.0.0.1 - - [15/Nov/2018:10:47:38 +0000] ""GET /favicon.ico HTTP/1.1"" 500 0 ""-"" ""-"" {code}"
94,AIRFLOW-3372,AIRFLOW,1542716581000,1560247189000,Bug,Closed,Blocker,1,6864,"Unable to start airflow scheduler *I have installed airflow in kubernetes cluster.When i am installing airflow ,i am unable to start the scheduler.The below is the log of scheduler container.* [2018-11-20 12:02:40,860] {{__init__.py:51}} INFO - Using executor SequentialExecutor [2018-11-20 12:02:40,973] {{cli_action_loggers.py:69}} ERROR - Failed on pre-execution callback using <function default_action_log at 0x7f26b730b620> Traceback (most recent call last): File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py"", line 1182, in _execute_context context) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/default.py"", line 470, in do_execute cursor.execute(statement, parameters) sqlite3.OperationalError: no such table: log The above exception was the direct cause of the following exception: Traceback (most recent call last): File ""/usr/local/lib/python3.5/dist-packages/airflow/utils/cli_action_loggers.py"", line 67, in on_pre_execution cb(**kwargs) File ""/usr/local/lib/python3.5/dist-packages/airflow/utils/cli_action_loggers.py"", line 99, in default_action_log session.commit() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 927, in commit self.transaction.commit() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 467, in commit self._prepare_impl() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 447, in _prepare_impl self.session.flush() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 2209, in flush self._flush(objects) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 2329, in _flush transaction.rollback(_capture_exception=True) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/langhelpers.py"", line 66, in __exit__ compat.reraise(exc_type, exc_value, exc_tb) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py"", line 187, in reraise raise value File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 2293, in _flush flush_context.execute() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/unitofwork.py"", line 389, in execute rec.execute(self) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/unitofwork.py"", line 548, in execute uow File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/persistence.py"", line 181, in save_obj mapper, table, insert) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/persistence.py"", line 835, in _emit_insert_statements execute(statement, params) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py"", line 945, in execute return meth(self, multiparams, params) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/sql/elements.py"", line 263, in _execute_on_connection return connection._execute_clauseelement(self, multiparams, params) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py"", line 1053, in _execute_clauseelement compiled_sql, distilled_params File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py"", line 1189, in _execute_context context) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py"", line 1402, in _handle_dbapi_exception exc_info File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py"", line 203, in raise_from_cause reraise(type(exception), exception, tb=exc_tb, cause=cause) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/util/compat.py"", line 186, in reraise raise value.with_traceback(tb) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/base.py"", line 1182, in _execute_context context) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/engine/default.py"", line 470, in do_execute cursor.execute(statement, parameters) sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: log [SQL: 'INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (?, ?, ?, ?, ?, ?, ?)'] [parameters: ('2018-11-20 12:02:40.969353', None, None, 'cli_scheduler', None, 'airflow', ' {""host_name"": ""airflow-airflow-scheduler-5b5f8b9549-89dmn"", ""full_command"": ""[\'/usr/local/bin/airflow\', \'scheduler\', \'-n\', \'-1\', \'-p\']""} ')] ____________ _____________ ____ |__( )_________ __/__ /________ __ ____ /| |_ /__ ___/_ /_ __ /_ __ _ | /| / / ___ ___ | / _ / _ __/ _ / / /_/ /_ |/ |/ / _/_/ |_/_/ /_/ /_/ /_/ ____/____/|__/ [2018-11-20 12:02:40,977] {{jobs.py:580}} *{color:#FF0000}ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1{color}* /usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py:513: SAWarning: Session's state has been changed on a non-active transaction - this state will be discarded. ""Session's state has been changed on "" Traceback (most recent call last): File ""/usr/local/bin/airflow"", line 32, in <module> args.func(args) File ""/usr/local/lib/python3.5/dist-packages/airflow/utils/cli.py"", line 74, in wrapper return f(*args, **kwargs) File ""/usr/local/lib/python3.5/dist-packages/airflow/bin/cli.py"", line 925, in scheduler job.run() File ""/usr/local/lib/python3.5/dist-packages/airflow/jobs.py"", line 196, in run session.commit() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 927, in commit self.transaction.commit() File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 465, in commit self._assert_active(prepared_ok=True) File ""/usr/local/lib/python3.5/dist-packages/sqlalchemy/orm/session.py"", line 276, in _assert_active % self._rollback_exception sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.OperationalError) no such table: log [SQL: 'INSERT INTO log (dttm, dag_id, task_id, event, execution_date, owner, extra) VALUES (?, ?, ?, ?, ?, ?, ?)'] [parameters: ('2018-11-20 12:02:40.969353', None, None, 'cli_scheduler', None, 'airflow', ' {""host_name"": ""airflow-airflow-scheduler-5b5f8b9549-89dmn"", ""full_command"": ""[\'/usr/local/bin/airflow\', \'scheduler\', \'-n\', \'-1\', \'-p\']""} ')] {color:#FF0000}*The pod status is like below*{color} [root@kubernetes-cpal-master-0 kube-airflow]# *kubectl get pod* NAME READY STATUS RESTARTS AGE airflow-airflow-flower-6668559cf7-ll5bn 1/1 Running 0 19m ~{color:#FF0000}*airflow-airflow-scheduler-5b5f8b9549-89dmn 0/1 CrashLoopBackOff 8 19m*{color}~ airflow-airflow-web-89d8fb554-9ztss 1/1 Running 0 19m airflow-airflow-web-89d8fb554-f4mbm 1/1 Running 0 19m airflow-airflow-worker-0 1/1 Running 0 19m airflow-postgresql-9df799579-swg8q 1/1 Running 0 19m airflow-redis-7d75b85f7-26lsx 1/1 Running 0 19m centos 0/1 CrashLoopBackOff 1278 29d logger-deepinsights-fluentd-759ffcfc5d-fjmml 1/1 Running 8 33d"
95,AIRFLOW-3400,AIRFLOW,1543246034000,1556014262000,Improvement,Closed,Blocker,1,350,"Remove python-nvd3 We are using python-nvd3 for generating charts from python side, and this pulls in slugify which by default uses a GPL'd dependency. This dep chian is the cause of needing to pass {{SLUGIFY_USES_TEXT_UNIDECODE=yes}} or similar, and that is annoying. So we should remove python-nvd3, probably still continue using nvd3.js and d3.js."
96,AIRFLOW-3443,AIRFLOW,1543962067000,1558148777000,Bug,Resolved,Blocker,1,507,"KubernetesPodOperator image_pull_secrets must be a valid parameter We've been successfully using the KubernetesPodOperator in our company with a local Docker registry, but when switching to a private repository such as Amazon ECR, Airflow wasn't able to pull the secrets from the cluster. I have made a change in the *make_pod()* function on *kubernetes_pod_operator.py* to support a new *image_pull_secrets* field. This works great on our end, and the community could benefit from it for the version 10.0.1"
97,AIRFLOW-3445,AIRFLOW,1544005709000,1550208929000,Bug,Closed,Blocker,1,1758,"MariaDB explicit_defaults_for_timestamp = 1 Does not work. {{Running into an issue when running }} {{`airflow upgradedb`}} {{ going from `1.9` -> `1.10.1`}} {{}} {code:java} `sqlalchemy.exc.OperationalError: (_mysql_exceptions.OperationalError) (1193, ""Unknown system variable 'explicit_defaults_for_timestamp'"") [SQL: 'SELECT @@explicit_defaults_for_timestamp']`{code} {{I saw this link on the airflow website.}} {{[https://airflow.readthedocs.io/en/stable/faq.html#how-to-fix-exception-global-variable-explicit-defaults-for-timestamp-needs-to-be-on-1|http://example.com]}} {{Here it says you can set}} {code:java} `explicit_defaults_for_timestamp = 1`{code} {{in the _my.cnf_ file. However I am using Mariadb and when I add this to the _my.cnf_ file the}} {noformat} mariadb.service{noformat} {{fails to start up. Has anyone else come across this issue?}} The output from {code:java} `SHOW VARIABLES like '%version%'`{code} was {code:java} `+-------------------------+----------------------+` `| Variable_name | Value |` `+-------------------------+----------------------+` `| innodb_version | 5.5.59-MariaDB-38.11 |` `| protocol_version | 10 |` `| slave_type_conversions | |` `| version | 5.5.60-MariaDB |` `| version_comment | MariaDB Server |` `| version_compile_machine | x86_64 |` `| version_compile_os | Linux |` `+-------------------------+----------------------+`{code} The MariaDB does not have the argument as it is a MySQL only feature. [https://mariadb.com/kb/en/library/system-variable-differences-between-mariadb-100-and-mysql-56/|http://example.com] There may need to be a check for MariaDB before upgrading, as mentioned by Ash in this Slack thread. [https://apache-airflow.slack.com/archives/CCQB40SQJ/p1543918149008100|http://example.com]"
98,AIRFLOW-3452,AIRFLOW,1544054302000,1547913927000,Improvement,Resolved,Blocker,1,549,"Cannot view dags at /home page I checked out the latest master branch(commit {{[9dce1f0|https://github.com/apache/incubator-airflow/commit/9dce1f0740f69af0ee86709a1a34a002b245aa3e]}}) and restarted my Airflow webserver. But I cannot view any dag at the home page. I inspected the frontend code and found there's a {{style=""display:none;""}} on the \{{main-content}}, and the source code says so at [https://github.com/apache/incubator-airflow/blob/master/airflow/www_rbac/templates/airflow/dags.html#L31] . Is this a known issue? How should I fix it?"
99,AIRFLOW-3630,AIRFLOW,1546594033000,1547066216000,Bug,Resolved,Blocker,1,395,"Google Cloud SQL query Operator cleanup will not close the connection on error When there is an error during Cloud SQL Query, there is a cleanup in post_execute_method. This cleanup is supposed to delete the connection, however it turns out that post_execute is not executed when execute() method throws an error (it was bad assumption). The connection should be closed always in finally clause."
100,AIRFLOW-3684,AIRFLOW,1547233014000,1559153088000,Bug,Open,Blocker,1,594,"Update bundled plugins to work with FAB-based UI We have one plugin in-tree (airflow.contrib.plugins.metastore_browser.main) that has a flask_blueprint - with the deprecation of the old UI in AIRFLOW-3303 this won't work anymore, so we should update that plugin. It might also be worth issuing a warning if a plugin has a {{admin_views}} attribute and no {{appbuilder_views}} (allow both to let a plugin support old and new Airflows.) We possibly need to update the plugin integration in the FAB-app to still support flask_blueprints (To support things that aren't views, such as static files)."
